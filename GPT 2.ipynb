{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of GPT 2.ipynb","provenance":[{"file_id":"1G8op_8AffQIlm6d2Yrd3Iz50EH-WslCD","timestamp":1590827239076}],"collapsed_sections":[],"authorship_tag":"ABX9TyOpRISgmU6fygcdwq/KMTD0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"iEJu1A1uW-Tv","colab_type":"text"},"source":["# Downloads open ai code"]},{"cell_type":"code","metadata":{"id":"HLd3uxggUpeX","colab_type":"code","outputId":"1b639d60-0282-4a5c-da43-b24b4ee24a45","executionInfo":{"status":"ok","timestamp":1584935637408,"user_tz":-330,"elapsed":12861,"user":{"displayName":"Edgar Monis","photoUrl":"","userId":"18244376460613966063"}},"colab":{"base_uri":"https://localhost:8080/","height":330}},"source":["!git clone https://github.com/openai/gpt-2.git \n","%cd gpt-2 \n","!pip install fire"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'gpt-2'...\n","remote: Enumerating objects: 230, done.\u001b[K\n","Receiving objects:   0% (1/230)   \rReceiving objects:   1% (3/230)   \rReceiving objects:   2% (5/230)   \rReceiving objects:   3% (7/230)   \rReceiving objects:   4% (10/230)   \rReceiving objects:   5% (12/230)   \rReceiving objects:   6% (14/230)   \rReceiving objects:   7% (17/230)   \rReceiving objects:   8% (19/230)   \rReceiving objects:   9% (21/230)   \rReceiving objects:  10% (23/230)   \rReceiving objects:  11% (26/230)   \rReceiving objects:  12% (28/230)   \rReceiving objects:  13% (30/230)   \rReceiving objects:  14% (33/230)   \rReceiving objects:  15% (35/230)   \rReceiving objects:  16% (37/230)   \rReceiving objects:  17% (40/230)   \rReceiving objects:  18% (42/230)   \rReceiving objects:  19% (44/230)   \rReceiving objects:  20% (46/230)   \rReceiving objects:  21% (49/230)   \rReceiving objects:  22% (51/230)   \rReceiving objects:  23% (53/230)   \rReceiving objects:  24% (56/230)   \rReceiving objects:  25% (58/230)   \rReceiving objects:  26% (60/230)   \rReceiving objects:  27% (63/230)   \rReceiving objects:  28% (65/230)   \rReceiving objects:  29% (67/230)   \rReceiving objects:  30% (69/230)   \rReceiving objects:  31% (72/230)   \rReceiving objects:  32% (74/230)   \rReceiving objects:  33% (76/230)   \rReceiving objects:  34% (79/230)   \rReceiving objects:  35% (81/230)   \rReceiving objects:  36% (83/230)   \rReceiving objects:  37% (86/230)   \rReceiving objects:  38% (88/230)   \rReceiving objects:  39% (90/230)   \rReceiving objects:  40% (92/230)   \rReceiving objects:  41% (95/230)   \rReceiving objects:  42% (97/230)   \rremote: Total 230 (delta 0), reused 0 (delta 0), pack-reused 230\u001b[K\n","Receiving objects:  43% (99/230)   \rReceiving objects:  44% (102/230)   \rReceiving objects:  45% (104/230)   \rReceiving objects:  46% (106/230)   \rReceiving objects:  47% (109/230)   \rReceiving objects:  48% (111/230)   \rReceiving objects:  49% (113/230)   \rReceiving objects:  50% (115/230)   \rReceiving objects:  51% (118/230)   \rReceiving objects:  52% (120/230)   \rReceiving objects:  53% (122/230)   \rReceiving objects:  54% (125/230)   \rReceiving objects:  55% (127/230)   \rReceiving objects:  56% (129/230)   \rReceiving objects:  57% (132/230)   \rReceiving objects:  58% (134/230)   \rReceiving objects:  59% (136/230)   \rReceiving objects:  60% (138/230)   \rReceiving objects:  61% (141/230)   \rReceiving objects:  62% (143/230)   \rReceiving objects:  63% (145/230)   \rReceiving objects:  64% (148/230)   \rReceiving objects:  65% (150/230)   \rReceiving objects:  66% (152/230)   \rReceiving objects:  67% (155/230)   \rReceiving objects:  68% (157/230)   \rReceiving objects:  69% (159/230)   \rReceiving objects:  70% (161/230)   \rReceiving objects:  71% (164/230)   \rReceiving objects:  72% (166/230)   \rReceiving objects:  73% (168/230)   \rReceiving objects:  74% (171/230)   \rReceiving objects:  75% (173/230)   \rReceiving objects:  76% (175/230)   \rReceiving objects:  77% (178/230)   \rReceiving objects:  78% (180/230)   \rReceiving objects:  79% (182/230)   \rReceiving objects:  80% (184/230)   \rReceiving objects:  81% (187/230)   \rReceiving objects:  82% (189/230)   \rReceiving objects:  83% (191/230)   \rReceiving objects:  84% (194/230)   \rReceiving objects:  85% (196/230)   \rReceiving objects:  86% (198/230)   \rReceiving objects:  87% (201/230)   \rReceiving objects:  88% (203/230)   \rReceiving objects:  89% (205/230)   \rReceiving objects:  90% (207/230)   \rReceiving objects:  91% (210/230)   \rReceiving objects:  92% (212/230)   \rReceiving objects:  93% (214/230)   \rReceiving objects:  94% (217/230)   \rReceiving objects:  95% (219/230)   \rReceiving objects:  96% (221/230)   \rReceiving objects:  97% (224/230)   \rReceiving objects:  98% (226/230)   \rReceiving objects:  99% (228/230)   \rReceiving objects: 100% (230/230)   \rReceiving objects: 100% (230/230), 4.38 MiB | 14.99 MiB/s, done.\n","Resolving deltas:   0% (0/118)   \rResolving deltas:   6% (8/118)   \rResolving deltas:  10% (12/118)   \rResolving deltas:  11% (14/118)   \rResolving deltas:  12% (15/118)   \rResolving deltas:  16% (20/118)   \rResolving deltas:  22% (27/118)   \rResolving deltas:  23% (28/118)   \rResolving deltas:  27% (32/118)   \rResolving deltas:  28% (34/118)   \rResolving deltas:  30% (36/118)   \rResolving deltas:  31% (37/118)   \rResolving deltas:  32% (38/118)   \rResolving deltas:  35% (42/118)   \rResolving deltas:  39% (47/118)   \rResolving deltas:  44% (52/118)   \rResolving deltas:  45% (54/118)   \rResolving deltas:  48% (57/118)   \rResolving deltas:  49% (58/118)   \rResolving deltas:  50% (59/118)   \rResolving deltas:  53% (63/118)   \rResolving deltas:  54% (64/118)   \rResolving deltas:  55% (65/118)   \rResolving deltas:  57% (68/118)   \rResolving deltas:  66% (78/118)   \rResolving deltas:  68% (81/118)   \rResolving deltas:  74% (88/118)   \rResolving deltas:  76% (90/118)   \rResolving deltas:  81% (96/118)   \rResolving deltas:  96% (114/118)   \rResolving deltas: 100% (118/118)   \rResolving deltas: 100% (118/118), done.\n","/content/gpt-2\n","Collecting fire\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n","\u001b[K     |████████████████████████████████| 81kB 12.5MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire) (1.12.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire) (1.1.0)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103528 sha256=6dca295a57354b2bd51ad9674647e5206ee368cf196775a9c16afc2f5756b026\n","  Stored in directory: /root/.cache/pip/wheels/31/9c/c0/07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n","Successfully built fire\n","Installing collected packages: fire\n","Successfully installed fire-0.2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yHBMJf8YVAof","colab_type":"code","outputId":"9efa5006-e0b1-4093-dcbe-fdbcbb58ade5","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python download_model.py 1558M\n","!sed -i 's/124M/1558M/g' src/interactive_conditional_samples.py\n","!sed -i 's/temperature=1/temperature=0.7/g' src/interactive_conditional_samples.py\n","!sed -i 's/top_k=0/top_k=40/g' src/interactive_conditional_samples.py\n","\n","!python src/interactive_conditional_samples.py"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\rFetching checkpoint:   0%|                                              | 0.00/77.0 [00:00<?, ?it/s]\rFetching checkpoint: 1.00kit [00:00, 1.06Mit/s]                                                     \n","\rFetching encoder.json:   0%|                                           | 0.00/1.04M [00:00<?, ?it/s]\rFetching encoder.json: 1.04Mit [00:00, 50.9Mit/s]                                                   \n","Fetching hparams.json: 1.00kit [00:00, 1.32Mit/s]                                                   \n","Fetching model.ckpt.data-00000-of-00001: 6.23Git [02:05, 49.5Mit/s]                                 \n","Fetching model.ckpt.index: 21.0kit [00:00, 13.9Mit/s]                                               \n","Fetching model.ckpt.meta: 1.84Mit [00:00, 56.8Mit/s]                                                \n","Fetching vocab.bpe: 457kit [00:00, 55.8Mit/s]                                                       \n","WARNING:tensorflow:From src/interactive_conditional_samples.py:57: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2020-03-23 03:58:30.159510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-03-23 03:58:30.196220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-23 03:58:30.196905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n","pciBusID: 0000:00:04.0\n","2020-03-23 03:58:30.200259: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-03-23 03:58:30.376787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-03-23 03:58:30.525720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-03-23 03:58:30.539009: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-03-23 03:58:30.824687: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-03-23 03:58:30.841404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-03-23 03:58:31.332381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-03-23 03:58:31.332573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-23 03:58:31.333309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-23 03:58:31.333857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-03-23 03:58:31.334389: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n","2020-03-23 03:58:31.348148: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000165000 Hz\n","2020-03-23 03:58:31.349161: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1fdaf40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-03-23 03:58:31.349192: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-03-23 03:58:31.544129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-23 03:58:31.544838: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1fdb100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-03-23 03:58:31.544872: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n","2020-03-23 03:58:31.545585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-23 03:58:31.545957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n","pciBusID: 0000:00:04.0\n","2020-03-23 03:58:31.546021: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-03-23 03:58:31.546040: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-03-23 03:58:31.546054: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-03-23 03:58:31.546069: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-03-23 03:58:31.546088: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-03-23 03:58:31.546102: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-03-23 03:58:31.546117: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-03-23 03:58:31.546168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-23 03:58:31.546602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-23 03:58:31.546944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-03-23 03:58:31.548875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-03-23 03:58:31.550003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-03-23 03:58:31.550034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-03-23 03:58:31.550044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-03-23 03:58:31.551076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-23 03:58:31.551495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-23 03:58:31.551835: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-03-23 03:58:31.551868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n","WARNING:tensorflow:From src/interactive_conditional_samples.py:58: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From src/interactive_conditional_samples.py:60: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.random.categorical` instead.\n","WARNING:tensorflow:From src/interactive_conditional_samples.py:68: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","Model prompt >>> tell me a joke\n","2020-03-23 04:11:27.019765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","======================================== SAMPLE 1 ========================================\n"," for me.\n","\n","[Laughter]\n","\n","So you know, I think we are really in a time now when the media, you know, and we all know the media can be very negative, and we are seeing that in many ways.\n","\n","So, I think it's important that people don't get too focused on the negative, because I think that the more positive that we have the better.\n","\n","So, I think the more positive we can be, the better we'll be.\n","\n","[Applause]\n","\n","Mr. President, thank you so much for being here.\n","\n","I really appreciate your willingness to share your thoughts and your vision.\n","\n","I really appreciate it.\n","\n","So, first of all, I want to thank you for being here.\n","\n","I want to thank Mike Pence for being here.\n","\n","I want to thank Chris Christie for being here.\n","\n","I want to thank the Cabinet for being here.\n","\n","And I want to thank the first lady for being here, for being so very kind, for being so generous, and for being such a great host.\n","\n","But I also want to thank everybody who has worked so hard to make this day possible.\n","\n","I want to thank the Secret Service.\n","\n","I want to thank the team that put this together.\n","\n","This was a very big day for me.\n","\n","This was a very big day for our country.\n","\n","And I really appreciate the work of everybody here.\n","\n","And I really appreciate the people who came, especially my wife Melania.\n","\n","This is a woman who has been married to a man for over 40 years.\n","\n","And I have to say, as I have been coming up with my questions, I could see her in my mind's eye as I began to speak and I could see that she was doing her very, very best to be there.\n","\n","And she's a great lady.\n","\n","And I just want to thank you, Melania, for being here.\n","\n","And I appreciate your very nice speech.\n","\n","It was terrific.\n","\n","And I'm so honored to meet with you all.\n","\n","And I also want to thank the media.\n","\n","You know, we've had a lot of press.\n","\n","And I know some of you are here from the television and the Internet.\n","\n","And I think it's important that we hear your voices.\n","\n","And I think it's really important that\n","================================================================================\n","Model prompt >>> The virus is really bad, the next steps are\n","======================================== SAMPLE 1 ========================================\n"," to remove the virus, and then to see how the virus will affect you.\"\n","\n","Tobias said the virus was transmitted by saliva, meaning it was transmitted by touching an infected person's mouth or nose without washing hands.\n","\n","\"It can spread through the air,\" he said. \"It is an airborne virus. It is an airborne infectious disease.\"\n","\n","Tobias said the virus had not been found in the air in the city of Winnipeg, but could be transmitted through the air.\n","\n","The Winnipeg Regional Health Authority said it is working with the Winnipeg Police Service to investigate the case.\n","\n","\"We are following this investigation very closely,\" said Dr. Dave Fenten, director of the Winnipeg Regional Health Authority.\n","\n","\"We are monitoring the Winnipeg Police Service for any possible exposure. We are working closely with the Winnipeg Regional Health Authority and the Winnipeg Fire Paramedic Service to determine if this is an outbreak of a new virus, or if this is a case of a new transmission.\"<|endoftext|>The American Civil Liberties Union (ACLU) filed a lawsuit against the NSA on Thursday claiming that the agency's collection of phone data is unconstitutional.\n","\n","According to the Associated Press, the ACLU filed the lawsuit in federal district court in Washington, D.C., on behalf of the American Civil Liberties Union and the American Civil Liberties Union Foundation of Northern California. The lawsuit, which seeks an injunction to halt the program, alleges that the NSA's collection of phone records is an illegal violation of the Fourth Amendment.\n","\n","\"The NSA's collection of this data is a search, a general warrant, and a search without a warrant in violation of the Fourth Amendment,\" said ACLU lawyer Steven R. Shapiro in a statement about the lawsuit. \"The government is attempting to avoid a confrontation with the courts by claiming a lack of authority to collect this data in the first place, and that is simply not true.\"\n","\n","The ACLU lawsuit was filed in the wake of reports that the NSA could have been collecting the phone records of millions of innocent Americans. The NSA, the New York Times and other news outlets reported, is collecting the phone records of tens of millions of Americans each year. The NSA has been collecting such data with phone companies' cooperation.\n","\n","The NSA is now investigating the claims made in the documents leaked to the Times and the Washington Post. The NSA has told reporters that it did not engage in any \"back door\" or \"secret back door\" surveillance operation, though some of the information it collected was not\n","================================================================================\n","Model prompt >>> "],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D3yzPjjeVKMB","colab_type":"code","outputId":"6257719a-9dfb-4bd2-d710-b2903ad7b77a","executionInfo":{"status":"ok","timestamp":1584849124353,"user_tz":-330,"elapsed":1948,"user":{"displayName":"Edgar Monis","photoUrl":"","userId":"18244376460613966063"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd .."],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M0_apt3mVQG8","colab_type":"text"},"source":["# Using minimaxir code \n","## It is used to get a more complete package with finetuning and output functionality built in"]},{"cell_type":"code","metadata":{"id":"BOhR-pYKX3Cj","colab_type":"code","outputId":"99a08f3d-1311-4013-9057-f26824f4cd08","executionInfo":{"status":"ok","timestamp":1584849291985,"user_tz":-330,"elapsed":8888,"user":{"displayName":"Edgar Monis","photoUrl":"","userId":"18244376460613966063"}},"colab":{"base_uri":"https://localhost:8080/","height":367}},"source":["!pip install gpt-2-simple"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting gpt-2-simple\n","  Downloading https://files.pythonhosted.org/packages/6f/e4/a90add0c3328eed38a46c3ed137f2363b5d6a07bf13ee5d5d4d1e480b8c3/gpt_2_simple-0.7.1.tar.gz\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2.21.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (4.38.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (1.18.2)\n","Collecting toposort\n","  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (3.0.4)\n","Building wheels for collected packages: gpt-2-simple\n","  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.7.1-cp36-none-any.whl size=23581 sha256=e860fde109bb31d0912e5ba48b2eafa4a43f4c4702c7d1a806a99948f0aba39b\n","  Stored in directory: /root/.cache/pip/wheels/0c/f8/23/b53ce437504597edff76bf9c3b8de08ad716f74f6c6baaa91a\n","Successfully built gpt-2-simple\n","Installing collected packages: toposort, gpt-2-simple\n","Successfully installed gpt-2-simple-0.7.1 toposort-1.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1hDI2BsvYOee","colab_type":"text"},"source":["# Generating shakespearean text as an example"]},{"cell_type":"code","metadata":{"id":"J7rg1Kf6Yae-","colab_type":"code","outputId":"2b1b3f79-2a98-4b14-d0fc-bf8ea4c5aa10","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import gpt_2_simple as gpt2\n","import os\n","import requests\n","\n","model_name = \"124M\"\n","if not os.path.isdir(os.path.join(\"models\", model_name)):\n","\tprint(f\"Downloading {model_name} model...\")\n","\tgpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /models/124M/\n","\n","\n","file_name = \"shakespeare.txt\"\n","if not os.path.isfile(file_name):\n","\turl = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n","\tdata = requests.get(url)\n","\t\n","\twith open(file_name, 'w') as f:\n","\t\tf.write(data.text)\n","    \n","\n","sess = gpt2.start_tf_sess()\n","gpt2.finetune(sess,\n","              file_name,\n","              model_name=model_name,\n","              steps=1000)   # steps is max number of training steps\n","\n","gpt2.generate(sess)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","Downloading 124M model...\n"],"name":"stdout"},{"output_type":"stream","text":["Fetching checkpoint: 1.05Mit [00:00, 542Mit/s]                                                      \n","Fetching encoder.json: 1.05Mit [00:00, 136Mit/s]                                                    \n","Fetching hparams.json: 1.05Mit [00:00, 665Mit/s]                                                    \n","Fetching model.ckpt.data-00000-of-00001: 498Mit [00:04, 99.7Mit/s]                                  \n","Fetching model.ckpt.index: 1.05Mit [00:00, 474Mit/s]                                                \n","Fetching model.ckpt.meta: 1.05Mit [00:00, 195Mit/s]                                                 \n","Fetching vocab.bpe: 1.05Mit [00:00, 193Mit/s]                                                       \n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Loading checkpoint models/124M/model.ckpt\n","INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/1 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loading dataset...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["dataset has 338025 tokens\n","Training...\n","[1 | 10.89] loss=4.11 avg=4.11\n","[2 | 14.10] loss=3.63 avg=3.87\n","[3 | 17.30] loss=3.81 avg=3.85\n","[4 | 20.50] loss=3.77 avg=3.83\n","[5 | 23.70] loss=3.60 avg=3.78\n","[6 | 26.90] loss=3.85 avg=3.79\n","[7 | 30.10] loss=3.65 avg=3.77\n","[8 | 33.31] loss=3.65 avg=3.76\n","[9 | 36.51] loss=3.67 avg=3.75\n","[10 | 39.71] loss=3.47 avg=3.72\n","[11 | 42.93] loss=3.36 avg=3.68\n","[12 | 46.14] loss=3.58 avg=3.67\n","[13 | 49.35] loss=3.47 avg=3.66\n","[14 | 52.56] loss=3.80 avg=3.67\n","[15 | 55.77] loss=3.67 avg=3.67\n","[16 | 58.98] loss=3.54 avg=3.66\n","[17 | 62.19] loss=3.39 avg=3.64\n","[18 | 65.42] loss=3.33 avg=3.62\n","[19 | 68.63] loss=3.39 avg=3.61\n","[20 | 71.84] loss=3.59 avg=3.61\n","[21 | 75.07] loss=3.73 avg=3.62\n","[22 | 78.28] loss=3.35 avg=3.60\n","[23 | 81.49] loss=3.59 avg=3.60\n","[24 | 84.70] loss=3.48 avg=3.60\n","[25 | 87.90] loss=3.55 avg=3.59\n","[26 | 91.12] loss=3.68 avg=3.60\n","[27 | 94.33] loss=3.35 avg=3.59\n","[28 | 97.54] loss=3.58 avg=3.59\n","[29 | 100.75] loss=3.62 avg=3.59\n","[30 | 103.97] loss=3.35 avg=3.58\n","[31 | 107.19] loss=3.59 avg=3.58\n","[32 | 110.39] loss=3.51 avg=3.58\n","[33 | 113.60] loss=3.25 avg=3.57\n","[34 | 116.82] loss=3.26 avg=3.56\n","[35 | 120.03] loss=3.35 avg=3.55\n","[36 | 123.25] loss=3.46 avg=3.55\n","[37 | 126.48] loss=3.16 avg=3.53\n","[38 | 129.70] loss=3.51 avg=3.53\n","[39 | 132.95] loss=3.33 avg=3.53\n","[40 | 136.17] loss=3.52 avg=3.53\n","[41 | 139.39] loss=3.40 avg=3.52\n","[42 | 142.61] loss=3.45 avg=3.52\n","[43 | 145.84] loss=3.36 avg=3.52\n","[44 | 149.05] loss=3.34 avg=3.51\n","[45 | 152.28] loss=3.41 avg=3.51\n","[46 | 155.50] loss=2.93 avg=3.49\n","[47 | 158.72] loss=3.11 avg=3.48\n","[48 | 161.94] loss=3.35 avg=3.48\n","[49 | 165.15] loss=3.22 avg=3.47\n","[50 | 168.38] loss=3.30 avg=3.47\n","[51 | 171.63] loss=3.48 avg=3.47\n","[52 | 174.86] loss=3.61 avg=3.47\n","[53 | 178.08] loss=3.45 avg=3.47\n","[54 | 181.32] loss=3.30 avg=3.47\n","[55 | 184.56] loss=3.28 avg=3.46\n","[56 | 187.79] loss=3.16 avg=3.46\n","[57 | 191.02] loss=3.41 avg=3.45\n","[58 | 194.25] loss=3.03 avg=3.44\n","[59 | 197.49] loss=3.05 avg=3.44\n","[60 | 200.73] loss=3.55 avg=3.44\n","[61 | 203.97] loss=3.24 avg=3.43\n","[62 | 207.21] loss=3.39 avg=3.43\n","[63 | 210.46] loss=2.97 avg=3.42\n","[64 | 213.71] loss=3.55 avg=3.43\n","[65 | 216.95] loss=3.42 avg=3.43\n","[66 | 220.18] loss=3.09 avg=3.42\n","[67 | 223.44] loss=3.22 avg=3.42\n","[68 | 226.70] loss=3.34 avg=3.41\n","[69 | 229.94] loss=3.22 avg=3.41\n","[70 | 233.20] loss=3.32 avg=3.41\n","[71 | 236.46] loss=2.96 avg=3.40\n","[72 | 239.71] loss=3.14 avg=3.39\n","[73 | 242.97] loss=3.09 avg=3.39\n","[74 | 246.22] loss=3.07 avg=3.38\n","[75 | 249.48] loss=3.13 avg=3.38\n","[76 | 252.73] loss=3.41 avg=3.38\n","[77 | 256.00] loss=3.40 avg=3.38\n","[78 | 259.24] loss=3.23 avg=3.38\n","[79 | 262.48] loss=3.31 avg=3.37\n","[80 | 265.75] loss=3.02 avg=3.37\n","[81 | 269.00] loss=3.25 avg=3.37\n","[82 | 272.26] loss=3.35 avg=3.37\n","[83 | 275.50] loss=3.16 avg=3.36\n","[84 | 278.75] loss=3.16 avg=3.36\n","[85 | 282.00] loss=3.45 avg=3.36\n","[86 | 285.26] loss=3.23 avg=3.36\n","[87 | 288.50] loss=2.98 avg=3.35\n","[88 | 291.77] loss=3.07 avg=3.35\n","[89 | 294.99] loss=2.99 avg=3.34\n","[90 | 298.25] loss=3.10 avg=3.34\n","[91 | 301.50] loss=3.04 avg=3.33\n","[92 | 304.75] loss=3.35 avg=3.33\n","[93 | 308.01] loss=3.21 avg=3.33\n","[94 | 311.26] loss=3.34 avg=3.33\n","[95 | 314.52] loss=3.14 avg=3.33\n","[96 | 317.77] loss=3.50 avg=3.33\n","[97 | 321.02] loss=3.36 avg=3.33\n","[98 | 324.26] loss=3.36 avg=3.33\n","[99 | 327.50] loss=3.00 avg=3.33\n","[100 | 330.75] loss=3.34 avg=3.33\n","======== SAMPLE 1 ========\n","Shay! how now, in thy name and your tongue, what hast thou here?\n","\n","MUM:\n","You have here the honour to swear my life.\n","\n","GLOUCESTER:\n","O, what, then. O, you! here you are:\n","I have sworn my life to the crown, my lord.\n","\n","MUM:\n","Ay, and you, my lord, the honour your crown holds on you.\n","\n","GLOUCESTER:\n","I'll kiss thee. I'll kiss thee.\n","\n","MUM:\n","My lord, kiss me.\n","\n","GLOUCESTER:\n","But you will not?\n","\n","MUM:\n","Not one of his majesty's.\n","\n","GLOUCESTER:\n","\n","MUM:\n","Ay, I know not, my lord.\n","\n","GLOUCESTER:\n","You have been gracious and patient;\n","And now, by your loving consent, you have\n","Become the great king; which is so, if you stay\n","with him.\n","\n","MUM:\n","The king of kings, I know not what.\n","But you, my lord, will be revenged.\n","\n","GLOUCESTER:\n","The crown of your majesty, if you can be so fair,\n","I have no doubt you will be his.\n","\n","MUM:\n","There were none. Even the queen?\n","\n","GLOUCESTER:\n","Marry or you will be his guest.\n","\n","MUM:\n","Ay.\n","\n","GLOUCESTER:\n","But the queen, as thou darest. What is she?\n","\n","MUM:\n","A man of royal blood.\n","\n","GLOUCESTER:\n","Nay, it is not her but the prince of the court.\n","\n","GLOUCESTER:\n","So, with thyself and thyself, thou shalt stand there.\n","\n","MUM:\n","Yes, so, and so shalt thou stand.\n","\n","GLOUCESTER:\n","Thou shalt stand there. This is a place where I do stand.\n","I want to be king there.\n","\n","GLOUCESTER:\n","You would not, my lord, the queen did not, as thou couldst know;\n","For thou didst do such a thing without thy consent.\n","\n","MUM:\n","No, she did--she did, thou didst not--for thou didst prove a king.\n","She would not, or thou didst prove but a king--for thou was king but by thyself\n","without consent.\n","\n","GLOUCESTER:\n","Thou cannot, my lord.\n","\n","MUM:\n","Then thou must not deny it.\n","It is not lawful.\n","\n","GLOUCESTER:\n","But thou wert against her.\n","\n","MUM:\n","The king is against thee.\n","\n","GLOUCESTER:\n","This, my lord, shall you be a king again?\n","\n","MUM:\n","Yes, to your good pleasure no less.\n","\n","GLOUCESTER:\n","Your good pleasure so much.\n","Your good pleasure but more.\n","\n","MUM:\n","Here I stand, my king, my lord, my queen\n","My lord's son,\n","My most beloved maid; and here, my queen:\n","My very dear queen, to tell thee this I am\n","I would so much as cry, I would cry.\n","My king, as thou wast, it cannot be tost me.\n","\n","MUM:\n","My king, thou art not mine but theirs.\n","As I have been to those I have been so, so I have been to thee.\n","Let my queen be my queen. A queen shall she hear.\n","I would not be so, my lord, my queen, unless thou wert withth or that.\n","Therefore, my lord.\n","To-day you shall speak in our country,\n","Thou queen shall not hear, if we should.\n","To-day thou art mine, but thyself.\n","\n","MUM:\n","Ay, thou must not know.\n","\n","GLOUCESTER:\n","For as I never heard the wisest word was thou wert against me,\n","So thou dost not.\n","\n","MUM:\n","No, no, thou dost not.\n","\n","GLOUCESTER:\n","If this be the truth, then thou dost be a coward.\n","If so, be one.\n","\n","MUM:\n","Ay, of the very worst.\n","\n","GLOUCESTER:\n","No, I would for this thou hast so much made me an old\n","good queen: thy queen be one to say this.\n","\n","LADY CAPULET:\n","Ay, no less than my own.\n","Why then, the way thou art, I would not wish to hear it.\n","But,\n","\n","[101 | 347.74] loss=3.23 avg=3.32\n","[102 | 351.00] loss=3.49 avg=3.33\n","[103 | 354.26] loss=3.11 avg=3.32\n","[104 | 357.52] loss=3.09 avg=3.32\n","[105 | 360.78] loss=3.17 avg=3.32\n","[106 | 364.02] loss=3.23 avg=3.32\n","[107 | 367.28] loss=2.99 avg=3.31\n","[108 | 370.53] loss=3.23 avg=3.31\n","[109 | 373.77] loss=3.23 avg=3.31\n","[110 | 377.02] loss=3.16 avg=3.31\n","[111 | 380.28] loss=3.02 avg=3.30\n","[112 | 383.53] loss=3.06 avg=3.30\n","[113 | 386.79] loss=3.11 avg=3.30\n","[114 | 390.04] loss=3.27 avg=3.30\n","[115 | 393.30] loss=2.96 avg=3.29\n","[116 | 396.55] loss=3.08 avg=3.29\n","[117 | 399.80] loss=3.04 avg=3.28\n","[118 | 403.06] loss=3.21 avg=3.28\n","[119 | 406.31] loss=3.12 avg=3.28\n","[120 | 409.57] loss=3.22 avg=3.28\n","[121 | 412.80] loss=3.13 avg=3.28\n","[122 | 416.06] loss=3.36 avg=3.28\n","[123 | 419.29] loss=3.17 avg=3.28\n","[124 | 422.53] loss=3.16 avg=3.28\n","[125 | 425.79] loss=3.05 avg=3.27\n","[126 | 429.02] loss=3.29 avg=3.27\n","[127 | 432.26] loss=2.93 avg=3.27\n","[128 | 435.49] loss=3.16 avg=3.27\n","[129 | 438.75] loss=3.00 avg=3.26\n","[130 | 441.99] loss=2.98 avg=3.26\n","[131 | 445.24] loss=3.04 avg=3.26\n","[132 | 448.51] loss=3.01 avg=3.25\n","[133 | 451.76] loss=2.93 avg=3.25\n","[134 | 455.03] loss=3.03 avg=3.24\n","[135 | 458.28] loss=3.04 avg=3.24\n","[136 | 461.54] loss=2.97 avg=3.24\n","[137 | 464.79] loss=3.09 avg=3.24\n","[138 | 468.04] loss=3.00 avg=3.23\n","[139 | 471.29] loss=3.09 avg=3.23\n","[140 | 474.55] loss=2.94 avg=3.23\n","[141 | 477.79] loss=2.80 avg=3.22\n","[142 | 481.04] loss=3.15 avg=3.22\n","[143 | 484.29] loss=3.13 avg=3.22\n","[144 | 487.55] loss=3.04 avg=3.22\n","[145 | 490.80] loss=3.08 avg=3.22\n","[146 | 494.04] loss=3.19 avg=3.22\n","[147 | 497.29] loss=2.93 avg=3.21\n","[148 | 500.54] loss=2.98 avg=3.21\n","[149 | 503.81] loss=3.07 avg=3.21\n","[150 | 507.05] loss=2.82 avg=3.20\n","[151 | 510.31] loss=3.01 avg=3.20\n","[152 | 513.56] loss=2.66 avg=3.19\n","[153 | 516.82] loss=3.36 avg=3.19\n","[154 | 520.07] loss=2.67 avg=3.19\n","[155 | 523.32] loss=2.95 avg=3.18\n","[156 | 526.58] loss=3.17 avg=3.18\n","[157 | 529.83] loss=2.86 avg=3.18\n","[158 | 533.09] loss=2.87 avg=3.18\n","[159 | 536.33] loss=3.09 avg=3.18\n","[160 | 539.57] loss=3.09 avg=3.17\n","[161 | 542.83] loss=2.96 avg=3.17\n","[162 | 546.06] loss=2.95 avg=3.17\n","[163 | 549.32] loss=3.42 avg=3.17\n","[164 | 552.56] loss=3.16 avg=3.17\n","[165 | 555.79] loss=3.19 avg=3.17\n","[166 | 559.04] loss=2.62 avg=3.17\n","[167 | 562.30] loss=3.11 avg=3.16\n","[168 | 565.55] loss=2.96 avg=3.16\n","[169 | 568.80] loss=3.11 avg=3.16\n","[170 | 572.04] loss=2.91 avg=3.16\n","[171 | 575.29] loss=3.03 avg=3.16\n","[172 | 578.52] loss=3.05 avg=3.16\n","[173 | 581.79] loss=2.86 avg=3.15\n","[174 | 585.04] loss=3.02 avg=3.15\n","[175 | 588.31] loss=2.93 avg=3.15\n","[176 | 591.57] loss=3.06 avg=3.15\n","[177 | 594.83] loss=3.10 avg=3.15\n","[178 | 598.09] loss=3.05 avg=3.15\n","[179 | 601.33] loss=2.83 avg=3.14\n","[180 | 604.61] loss=2.98 avg=3.14\n","[181 | 607.84] loss=3.05 avg=3.14\n","[182 | 611.10] loss=3.14 avg=3.14\n","[183 | 614.34] loss=2.90 avg=3.14\n","[184 | 617.59] loss=2.94 avg=3.13\n","[185 | 620.84] loss=3.01 avg=3.13\n","[186 | 624.09] loss=2.88 avg=3.13\n","[187 | 627.35] loss=2.95 avg=3.13\n","[188 | 630.60] loss=3.03 avg=3.13\n","[189 | 633.86] loss=3.38 avg=3.13\n","[190 | 637.12] loss=3.03 avg=3.13\n","[191 | 640.36] loss=2.84 avg=3.12\n","[192 | 643.62] loss=3.03 avg=3.12\n","[193 | 646.87] loss=3.11 avg=3.12\n","[194 | 650.13] loss=2.94 avg=3.12\n","[195 | 653.37] loss=2.78 avg=3.12\n","[196 | 656.61] loss=2.85 avg=3.11\n","[197 | 659.87] loss=2.91 avg=3.11\n","[198 | 663.12] loss=2.98 avg=3.11\n","[199 | 666.37] loss=2.93 avg=3.11\n","[200 | 669.62] loss=3.02 avg=3.11\n","======== SAMPLE 1 ========\n","\n","\n","SICINIUS:\n","I do the work.\n","\n","Citizens:\n","Do it!\n","\n","SAMPSON:\n","Amen.\n","\n","Citizens:\n","He must.\n","\n","SICINIUS:\n","'Signior Baptista.'\n","\n","Citizens:\n","What!\n","\n","SAMPSON:\n","A man too wise to be a fool.\n","\n","SICINIUS:\n","No more lies.\n","\n","Citizens:\n","He's a good sir; but, sir, we must not lie;\n","so, 'Sir, be as quick as our time can do you honour.'\n","\n","SICINIUS:\n","Sir, in your opinion, it's best.\n","\n","Citizens:\n","He says you are too slow! I'll bring my time with it.\n","\n","CAPULET:\n","He's too late.\n","\n","Citizens:\n","Where is Padua?\n","\n","SAMPSON:\n","There's no one that will come.\n","\n","CAPULET:\n","Well, good Padua, he will not come to us.\n","He will not speak to us.\n","All is calm.\n","\n","CAPULET:\n","Here's the thing: if you can do this, what dost thou fear?\n","You, Camillo, do 't.\n","\n","CAPULET:\n","He's none.\n","\n","SAMPSON:\n","He's none.\n","\n","CAMILLO:\n","Well, be thou sure of that, my friend. Signior Baptista?\n","\n","Citizens:\n","I am a witness.\n","\n","SAMPSON:\n","Signior Baptista? Signior Baptista?\n","\n","CAPULET:\n","Signior Baptista! Signior Baptista?\n","\n","SAMPSON:\n","Signior Baptista: Signior Baptista?\n","\n","CAPULET:\n","Signior Baptista! Signior Baptista?\n","\n","SAMPSON:\n","Signior Baptista: Signior Baptista?\n","\n","CAPULET:\n","Signior Baptista: Signior Baptista?\n","\n","CAPULET:\n","Signior Baptista: Signior Baptista?\n","Signior Baptista? Signior Baptista?\n","Signior Baptista? Signior Baptista? This is nothing; all is well:\n","this shall be our witness, as well as his; there shall be no blemish.\n","\n","SICINIUS:\n","O you valiant fellows, you will not allow yourself to\n","compliment this way of honour. Signior\n","Baptista, you, Camillo, you, Padua, you, Camillo, you,\n","Camillo, you, Camillo, you, Camillo, you, Camillo!\n","\n","Padua:\n","I, what, what!\n","\n","CAPULET:\n","'Signior Baptista, here I am. Signior,\n","'Here I am,' I say, Signior,\n","'Here I am,' I say, Signior,\n","'Here I am,' I say, Signior,\n","'Here I am,' I say, Camillo, thou, me and\n","this:\n","'Signior, here I am,' I say, Signior,\n","'Here I am,' I say, Camillo, thou, me and\n","this:\n","'Signior, here I am,' I say, Signior,\n","'Here I am,' I say, Camillo, thou, me and\n","this:\n","Benedicite:\n","If a word may do thee good, Signior, thou shalt not hold it\n","in the mouth to which I send thee: but as for Capulets,\n","he'll bite thee in it too. Signior, Camillo, here\n","I come! why, what's this? Signior,\n","I come. Why, what's this? Signior, Camillo, here\n","I come! why,\" quoth Padua.\n","\n","CAPULET:\n","What is Signior?\n","\n","CAPULET:\n","What is Signior?\n","\n","CAPULET:\n","Signior!\n","\n","CAPULET:\n","Signior!\n","\n","SICINIUS:\n","No.\n","\n","CAPULET:\n","Signior!\n","\n","CAPULET:\n","Signior!\n","\n","CAPULET:\n","Signior!\n","\n","SICINIUS:\n","No good.\n","\n","CAPULET:\n","SICINIUS:\n","No word.\n","\n","CAPULET:\n","Signior!\n","\n","SAMPSON:\n","The good man!\n","\n","CAPULET:\n","Signior!\n","\n","SAMPSON:\n","Good man!\n","\n","CAPULET:\n","Messenger,\n","Sir, I do wish a day's absence\n","From these dame's presence.\n","\n","SAMPSON:\n","No good.\n","\n","CAPULET\n","\n","[201 | 685.43] loss=3.00 avg=3.11\n","[202 | 688.68] loss=2.55 avg=3.10\n","[203 | 691.91] loss=2.92 avg=3.10\n","[204 | 695.16] loss=2.70 avg=3.09\n","[205 | 698.39] loss=2.75 avg=3.09\n","[206 | 701.64] loss=2.80 avg=3.08\n","[207 | 704.90] loss=2.87 avg=3.08\n","[208 | 708.15] loss=2.86 avg=3.08\n","[209 | 711.40] loss=2.72 avg=3.08\n","[210 | 714.65] loss=3.08 avg=3.08\n","[211 | 717.89] loss=2.68 avg=3.07\n","[212 | 721.13] loss=2.90 avg=3.07\n","[213 | 724.38] loss=2.69 avg=3.07\n","[214 | 727.65] loss=3.00 avg=3.06\n","[215 | 730.90] loss=2.80 avg=3.06\n","[216 | 734.16] loss=2.72 avg=3.06\n","[217 | 737.41] loss=2.72 avg=3.05\n","[218 | 740.67] loss=2.67 avg=3.05\n","[219 | 743.92] loss=2.79 avg=3.05\n","[220 | 747.18] loss=2.85 avg=3.04\n","[221 | 750.43] loss=2.88 avg=3.04\n","[222 | 753.67] loss=2.88 avg=3.04\n","[223 | 756.90] loss=2.71 avg=3.04\n","[224 | 760.14] loss=2.73 avg=3.03\n","[225 | 763.40] loss=2.90 avg=3.03\n","[226 | 766.66] loss=2.91 avg=3.03\n","[227 | 769.90] loss=2.87 avg=3.03\n","[228 | 773.15] loss=2.86 avg=3.03\n","[229 | 776.40] loss=3.01 avg=3.03\n","[230 | 779.66] loss=2.49 avg=3.02\n","[231 | 782.92] loss=3.05 avg=3.02\n","[232 | 786.17] loss=2.71 avg=3.02\n","[233 | 789.42] loss=2.71 avg=3.01\n","[234 | 792.67] loss=2.92 avg=3.01\n","[235 | 795.91] loss=2.75 avg=3.01\n","[236 | 799.17] loss=2.81 avg=3.01\n","[237 | 802.42] loss=2.78 avg=3.01\n","[238 | 805.67] loss=2.85 avg=3.00\n","[239 | 808.93] loss=3.03 avg=3.00\n","[240 | 812.18] loss=2.71 avg=3.00\n","[241 | 815.43] loss=2.88 avg=3.00\n","[242 | 818.68] loss=2.77 avg=3.00\n","[243 | 821.94] loss=2.69 avg=2.99\n","[244 | 825.19] loss=2.95 avg=2.99\n","[245 | 828.43] loss=2.73 avg=2.99\n","[246 | 831.68] loss=2.95 avg=2.99\n","[247 | 834.95] loss=2.78 avg=2.99\n","[248 | 838.21] loss=2.75 avg=2.99\n","[249 | 841.46] loss=2.78 avg=2.98\n","[250 | 844.71] loss=2.78 avg=2.98\n","[251 | 847.95] loss=2.93 avg=2.98\n","[252 | 851.18] loss=2.61 avg=2.98\n","[253 | 854.43] loss=2.80 avg=2.97\n","[254 | 857.69] loss=3.04 avg=2.97\n","[255 | 860.93] loss=2.51 avg=2.97\n","[256 | 864.18] loss=2.86 avg=2.97\n","[257 | 867.43] loss=2.55 avg=2.96\n","[258 | 870.68] loss=2.77 avg=2.96\n","[259 | 873.95] loss=2.67 avg=2.96\n","[260 | 877.21] loss=2.69 avg=2.96\n","[261 | 880.47] loss=2.61 avg=2.95\n","[262 | 883.73] loss=2.70 avg=2.95\n","[263 | 886.97] loss=2.58 avg=2.95\n","[264 | 890.23] loss=2.58 avg=2.94\n","[265 | 893.48] loss=2.84 avg=2.94\n","[266 | 896.75] loss=2.60 avg=2.94\n","[267 | 899.99] loss=2.79 avg=2.94\n","[268 | 903.25] loss=2.69 avg=2.93\n","[269 | 906.50] loss=2.55 avg=2.93\n","[270 | 909.75] loss=2.69 avg=2.93\n","[271 | 913.01] loss=2.64 avg=2.92\n","[272 | 916.26] loss=2.76 avg=2.92\n","[273 | 919.52] loss=2.76 avg=2.92\n","[274 | 922.75] loss=2.64 avg=2.92\n","[275 | 926.00] loss=2.70 avg=2.91\n","[276 | 929.26] loss=2.87 avg=2.91\n","[277 | 932.51] loss=2.86 avg=2.91\n","[278 | 935.76] loss=2.71 avg=2.91\n","[279 | 939.02] loss=2.61 avg=2.91\n","[280 | 942.28] loss=2.59 avg=2.90\n","[281 | 945.54] loss=2.75 avg=2.90\n","[282 | 948.77] loss=2.63 avg=2.90\n","[283 | 952.02] loss=2.63 avg=2.90\n","[284 | 955.27] loss=2.61 avg=2.89\n","[285 | 958.53] loss=2.75 avg=2.89\n","[286 | 961.78] loss=2.47 avg=2.89\n","[287 | 965.03] loss=2.69 avg=2.89\n","[288 | 968.29] loss=2.56 avg=2.88\n","[289 | 971.53] loss=2.69 avg=2.88\n","[290 | 974.77] loss=2.80 avg=2.88\n","[291 | 978.03] loss=2.78 avg=2.88\n","[292 | 981.29] loss=2.69 avg=2.88\n","[293 | 984.54] loss=2.39 avg=2.87\n","[294 | 987.79] loss=2.72 avg=2.87\n","[295 | 991.05] loss=2.64 avg=2.87\n","[296 | 994.31] loss=2.69 avg=2.87\n","[297 | 997.56] loss=2.82 avg=2.86\n","[298 | 1000.81] loss=2.74 avg=2.86\n","[299 | 1004.07] loss=2.53 avg=2.86\n","[300 | 1007.32] loss=2.61 avg=2.86\n","======== SAMPLE 1 ========\n"," go!\n","We'll meet thee in her grave: for this\n","is the very thing in my heart I was most opposed to\n","thine falling, as thou art to 's.\n","\n","First Messenger:\n","You speak unkindly in mine heart, O son of a whore!\n","\n","Third Messenger:\n","You say thy heart is full of hate in thee:\n","Thou speak'st such hateful language with scorn\n","that thou wilt burst thy neck.\n","\n","Second Messenger:\n","You would do well with thy head, as with a fork\n","That has been struck and wounded: then you speak,\n","and do wrong with it, and do so with an angry word;\n","And then do justice with your heart; then you say\n","this is the most horrible sin of your life\n","And shall stain your heart with wrath.\n","\n","Third Messenger:\n","Do you not believe it? why, O son of a whore,\n","You do believe a vice; but if thou deny it,\n","Thou break'st the heart of a righteous man.\n","O, for thee, it is a gross sin that I speak!\n","\n","First Messenger:\n","Why, father, let me speak, if thou deny'st the truth\n","Of the sin of such wicked men as thyself.\n","\n","Second Messenger:\n","O, then 'tis a sin, and thy slanderous word\n","Tongues thee too steep: but if thou confess\n","This word, O thou wretch, I'll cut thee off from\n","The happy state which thou hast created thyself,\n","The world, and all the kindred that thou hast\n","Made possible by thy slanderous tongue. O\n","boldness! and as boldness\n","Shall shorten the woe that thou hast created!' O,\n","thy word is a sin, and thou dost put it off.\n","\n","Third Messenger:\n","You do, O brave son! I hear\n","The parlous-voiced mother in her son's voice.\n","\n","First Messenger:\n","That word thou have put off, which is like a sin,\n","Shall shorten't a word of this slanderous word:\n","You wilt offend the very heart that calls thee o'\n","the wager? O my soul!\n","\n","Second Messenger:\n","I have heard it again, and would have found it more,\n","The word was out. The word was put off.\n","\n","Third Messenger:\n","And I, for my heart was in the name of that word.\n","O God! look you frown upon the word.\n","\n","First Messenger:\n","Well, go with me; I'll go with thee.\n","\n","Second:\n","O prince of the maidens! thou hast the queen's ear!\n","\n","Third:\n","My queen is my sweet son! O prince of the maidens!\n","\n","Fourth (in the queen's ear):\n","I will, my queen; and when thou hast done,\n","I will stand before my throne, that thou mayst hear\n","Me; and therefore 'twere your business.\n","\n","First Messenger:\n","Ay, my sovereign; and therefore 'twere mine business.\n","\n","Second:\n","And that thou shouldst hear me.\n","\n","Third:\n","Ay, my sovereign.\n","\n","Fourth:\n","I wish you well of it: yet the queen's ear\n","Is rich in earldom, if not earldom.\n","\n","First:\n","Hast thou heard the queen have the dowry heard me?\n","\n","Second:\n","I do; 'twere a word or two of mine.\n","\n","Third:\n","She hath the dowry heard me? Then tell me, if thou\n","Shouldst hear me a word and thy hand did touch it,\n","Would thou hear me touch a word? Then speak this:\n","A mother's love may be heard from my hand,\n","The queen's earle may be heard from her\n","'Twere mine.\n","\n","First:\n","I dare not say 'twas hers; for she is made\n","A fool's instrument; thus, 'tis she made, she\n","I shall use, my sweet, good mother's love.\n","3 KING HENRY VI\n","\n","NORTHUMBERLAND:\n","What now, York?\n","\n","Second:\n","What, cousin, shall we hear you speak?\n","\n","First:\n","You speak in the morning time; then let us hear you\n","Meet in the morning: I'll stand here till\n","Your speech be long-winded.\n","\n","Second:\n","Will't please you be so short?\n","\n","First:\n","As thou hast said, I will meet thee in her\n","Cremation grave, or let him have time for his\n","Exercitories: that doth me happy.\n","\n","Second:\n","'Tis my hope in her a grave, I hope.\n","\n","First:\n","I do, my queen: and so, so, so 'twere\n","The\n","\n","[301 | 1022.90] loss=2.63 avg=2.85\n","[302 | 1026.17] loss=2.49 avg=2.85\n","[303 | 1029.41] loss=2.19 avg=2.84\n","[304 | 1032.68] loss=2.61 avg=2.84\n","[305 | 1035.93] loss=2.37 avg=2.84\n","[306 | 1039.19] loss=2.83 avg=2.84\n","[307 | 1042.45] loss=2.47 avg=2.83\n","[308 | 1045.71] loss=2.58 avg=2.83\n","[309 | 1048.96] loss=2.73 avg=2.83\n","[310 | 1052.22] loss=2.44 avg=2.82\n","[311 | 1055.48] loss=2.67 avg=2.82\n","[312 | 1058.73] loss=2.84 avg=2.82\n","[313 | 1061.98] loss=2.56 avg=2.82\n","[314 | 1065.23] loss=2.34 avg=2.82\n","[315 | 1068.48] loss=2.60 avg=2.81\n","[316 | 1071.75] loss=2.45 avg=2.81\n","[317 | 1074.99] loss=2.83 avg=2.81\n","[318 | 1078.25] loss=2.64 avg=2.81\n","[319 | 1081.50] loss=2.52 avg=2.81\n","[320 | 1084.74] loss=2.51 avg=2.80\n","[321 | 1087.99] loss=2.43 avg=2.80\n","[322 | 1091.24] loss=2.83 avg=2.80\n","[323 | 1094.48] loss=2.52 avg=2.80\n","[324 | 1097.72] loss=2.45 avg=2.79\n","[325 | 1100.96] loss=2.69 avg=2.79\n","[326 | 1104.19] loss=2.94 avg=2.79\n","[327 | 1107.43] loss=2.48 avg=2.79\n","[328 | 1110.68] loss=2.56 avg=2.79\n","[329 | 1113.94] loss=2.47 avg=2.78\n","[330 | 1117.19] loss=2.50 avg=2.78\n","[331 | 1120.45] loss=2.25 avg=2.78\n","[332 | 1123.71] loss=2.10 avg=2.77\n","[333 | 1126.96] loss=2.57 avg=2.77\n","[334 | 1130.22] loss=2.41 avg=2.76\n","[335 | 1133.47] loss=2.15 avg=2.76\n","[336 | 1136.72] loss=2.23 avg=2.75\n","[337 | 1139.99] loss=2.48 avg=2.75\n","[338 | 1143.25] loss=2.59 avg=2.75\n","[339 | 1146.51] loss=2.54 avg=2.74\n","[340 | 1149.76] loss=2.49 avg=2.74\n","[341 | 1153.01] loss=2.39 avg=2.74\n","[342 | 1156.25] loss=2.38 avg=2.73\n","[343 | 1159.50] loss=2.47 avg=2.73\n","[344 | 1162.75] loss=1.94 avg=2.72\n","[345 | 1166.01] loss=2.58 avg=2.72\n","[346 | 1169.25] loss=2.34 avg=2.72\n","[347 | 1172.52] loss=2.43 avg=2.71\n","[348 | 1175.76] loss=2.73 avg=2.72\n","[349 | 1179.02] loss=2.69 avg=2.71\n","[350 | 1182.28] loss=2.39 avg=2.71\n","[351 | 1185.52] loss=2.60 avg=2.71\n","[352 | 1188.78] loss=2.53 avg=2.71\n","[353 | 1192.03] loss=2.80 avg=2.71\n","[354 | 1195.30] loss=2.29 avg=2.71\n","[355 | 1198.53] loss=2.51 avg=2.70\n","[356 | 1201.78] loss=2.28 avg=2.70\n","[357 | 1205.04] loss=2.31 avg=2.69\n","[358 | 1208.27] loss=2.12 avg=2.69\n","[359 | 1211.52] loss=2.21 avg=2.68\n","[360 | 1214.78] loss=2.31 avg=2.68\n","[361 | 1218.03] loss=2.38 avg=2.68\n","[362 | 1221.26] loss=2.29 avg=2.67\n","[363 | 1224.52] loss=2.69 avg=2.67\n","[364 | 1227.77] loss=2.40 avg=2.67\n","[365 | 1231.03] loss=2.49 avg=2.67\n","[366 | 1234.28] loss=2.38 avg=2.67\n","[367 | 1237.54] loss=2.24 avg=2.66\n","[368 | 1240.79] loss=2.30 avg=2.66\n","[369 | 1244.04] loss=2.40 avg=2.65\n","[370 | 1247.30] loss=2.32 avg=2.65\n","[371 | 1250.54] loss=2.40 avg=2.65\n","[372 | 1253.81] loss=2.72 avg=2.65\n","[373 | 1257.06] loss=2.66 avg=2.65\n","[374 | 1260.32] loss=2.75 avg=2.65\n","[375 | 1263.57] loss=2.79 avg=2.65\n","[376 | 1266.82] loss=2.49 avg=2.65\n","[377 | 1270.07] loss=2.27 avg=2.65\n","[378 | 1273.31] loss=2.39 avg=2.64\n","[379 | 1276.56] loss=2.28 avg=2.64\n","[380 | 1279.82] loss=2.54 avg=2.64\n","[381 | 1283.07] loss=2.24 avg=2.64\n","[382 | 1286.33] loss=2.20 avg=2.63\n","[383 | 1289.58] loss=2.41 avg=2.63\n","[384 | 1292.83] loss=2.49 avg=2.63\n","[385 | 1296.09] loss=2.21 avg=2.62\n","[386 | 1299.33] loss=2.04 avg=2.62\n","[387 | 1302.60] loss=2.43 avg=2.61\n","[388 | 1305.85] loss=2.26 avg=2.61\n","[389 | 1309.11] loss=2.43 avg=2.61\n","[390 | 1312.34] loss=2.39 avg=2.61\n","[391 | 1315.59] loss=2.28 avg=2.60\n","[392 | 1318.85] loss=2.41 avg=2.60\n","[393 | 1322.10] loss=2.26 avg=2.60\n","[394 | 1325.35] loss=2.56 avg=2.60\n","[395 | 1328.59] loss=1.94 avg=2.59\n","[396 | 1331.84] loss=2.03 avg=2.59\n","[397 | 1335.09] loss=2.73 avg=2.59\n","[398 | 1338.33] loss=2.14 avg=2.58\n","[399 | 1341.58] loss=2.07 avg=2.58\n","[400 | 1344.82] loss=1.95 avg=2.57\n","======== SAMPLE 1 ========\n","\n","I have not anointed myself\n","To know what he hath in me, and what I cannot know.\n","If we did know the truth of what he\n","has to say, we should call it a falsehood.\n","\n","Nurse:\n","And we call it a falsehood, but we had not\n","to put any one on.\n","\n","HORTENSIO:\n","What's your lie, or your lie-proof, to make us all\n","feign it?\n","\n","Nurse:\n","That you would know that I am a friar, and I am a woman.\n","\n","HORTENSIO:\n","You know it withal. But, boy, I must confess an evil.\n","Let me confess, as you dare infer, it lies.\n","\n","Nurse:\n","I must confess it, and I will answer it by oath.\n","\n","HORTENSIO:\n","I shall answer thee for it, man, thou canst not tell for\n","her.\n","\n","Nurse:\n","O, by heaven, thou canst: and if thou canst, thou dost,\n","by his oath, betray me as a man.\n","\n","HORTENSIO:\n","Take him to our church, then, and let him swear\n","he is thou.\n","\n","Nurse:\n","He will, sir.\n","\n","HORTENSIO:\n","But tell us whence he came to this house, or what-have-not he\n","wore here.\n","\n","Nurse:\n","I must; I do, sir. To-night, as we have heard it,\n","Bishop Biondello is coming to help meet the mayor.\n","\n","BIONDELLO:\n","I warrant you, sir, his oath is such as will\n","not be broken. But, since the friar came hither and\n","not yet our priest, I warrant you, in writing to\n","him, at your office, ere the time when he shall\n","be ordained a priest, he must come to meet the mayor.\n","I think he will: ere he shall come, let him come to meet them.\n","\n","BIONDELLO:\n","So it seemeth, by his holy commission,\n","I am sent to attend the mayor: and if he\n","do come to me within the limits of two days\n","he shall tell me by our witness, as the office\n","complices in writing: yet in faith, ere the mayor\n","may come near us, the priest shall hear it and\n","wonder what may follow when Bishop Biondello does.\n","\n","LUCENTIO:\n","\n","RICHMOND:\n","What say you to that?\n","\n","PERDITA:\n","For what purpose?\n","\n","HORTENSIO:\n","I'll tell you the reason, sir, that you may not come to me.\n","\n","VINCENTIO:\n","I know it well, sir, because I see it thus: we came\n","unto the bishop; and did stumble upon him, he was so\n","delighted with his report, that we did give him away\n","to strew his carport with, among other things, beads\n","and rings.\n","\n","LUCENTIO:\n","\n","VINCENTIO:\n","And he has more bracelets in his carport\n","now than any thing in Italy.\n","\n","LUCENTIO:\n","\n","VINCENTIO:\n","And that the mayor, if he come to him as well\n","as here to Rome, shall prove such as he and us shall\n","experience together.\n","\n","HORTENSIO:\n","You say, sir, 'may he come to us,' and 'shall,'\n","and 'shall' shall prove a thing to him.\n","\n","VINCENTIO:\n","'But a little while, gentle gentleman,'\n","and 'but a pittance,', is all I need.\n","'But a little while, gentle gentlemen,'\n","and 'but a little while,', shall prove 'a very big sum:'\n","you need not to add that 'may,' 'may not,' and 'may not,'\n","to give a thousand, if you will; the rest are too much\n","big.\n","\n","LUCENTIO:\n","You have little faith, sir, to go so far. You mean,\n","beyond all suspicion, to steal to the bishop?\n","\n","HORTENSIO:\n","In very great measure: if 'shall' be less,\n","'shall' shall be all. What 'shall' shall I say,\n","but 'shall there be in this house?'\n","\n","VINCENTIO:\n","Where were these beads? wherefore these beads?\n","\n","LUCENTIO:\n","I come to tell thee what they are, good man: these\n","beads are my habitations; I come to tell thee\n","how they shall appear, if any need there be.\n","\n","BAPTISTA:\n","I\n","\n","[401 | 1360.48] loss=2.50 avg=2.57\n","[402 | 1363.74] loss=2.21 avg=2.57\n","[403 | 1366.98] loss=2.10 avg=2.56\n","[404 | 1370.22] loss=2.55 avg=2.56\n","[405 | 1373.46] loss=1.97 avg=2.56\n","[406 | 1376.71] loss=2.45 avg=2.55\n","[407 | 1379.96] loss=2.54 avg=2.55\n","[408 | 1383.22] loss=2.35 avg=2.55\n","[409 | 1386.47] loss=2.16 avg=2.55\n","[410 | 1389.72] loss=2.17 avg=2.54\n","[411 | 1392.97] loss=2.44 avg=2.54\n","[412 | 1396.22] loss=1.97 avg=2.54\n","[413 | 1399.47] loss=2.30 avg=2.54\n","[414 | 1402.72] loss=2.04 avg=2.53\n","[415 | 1405.98] loss=2.28 avg=2.53\n","[416 | 1409.23] loss=2.15 avg=2.52\n","[417 | 1412.46] loss=2.23 avg=2.52\n","[418 | 1415.70] loss=2.15 avg=2.52\n","[419 | 1418.95] loss=2.00 avg=2.51\n","[420 | 1422.20] loss=2.34 avg=2.51\n","[421 | 1425.46] loss=2.30 avg=2.51\n","[422 | 1428.71] loss=2.15 avg=2.50\n","[423 | 1431.95] loss=2.31 avg=2.50\n","[424 | 1435.18] loss=2.38 avg=2.50\n","[425 | 1438.43] loss=2.21 avg=2.50\n","[426 | 1441.69] loss=1.88 avg=2.49\n","[427 | 1444.96] loss=2.18 avg=2.49\n","[428 | 1448.21] loss=2.07 avg=2.48\n","[429 | 1451.47] loss=2.27 avg=2.48\n","[430 | 1454.72] loss=2.34 avg=2.48\n","[431 | 1457.98] loss=2.09 avg=2.48\n","[432 | 1461.22] loss=1.89 avg=2.47\n","[433 | 1464.49] loss=1.91 avg=2.47\n","[434 | 1467.74] loss=2.17 avg=2.46\n","[435 | 1470.99] loss=2.15 avg=2.46\n","[436 | 1474.25] loss=2.34 avg=2.46\n","[437 | 1477.50] loss=2.14 avg=2.45\n","[438 | 1480.74] loss=1.98 avg=2.45\n","[439 | 1483.98] loss=1.99 avg=2.45\n","[440 | 1487.22] loss=2.08 avg=2.44\n","[441 | 1490.48] loss=2.10 avg=2.44\n","[442 | 1493.73] loss=2.06 avg=2.43\n","[443 | 1496.98] loss=2.02 avg=2.43\n","[444 | 1500.24] loss=2.08 avg=2.43\n","[445 | 1503.49] loss=2.05 avg=2.42\n","[446 | 1506.74] loss=2.07 avg=2.42\n","[447 | 1510.00] loss=2.01 avg=2.41\n","[448 | 1513.26] loss=2.26 avg=2.41\n","[449 | 1516.53] loss=1.96 avg=2.41\n","[450 | 1519.79] loss=1.81 avg=2.40\n","[451 | 1523.04] loss=1.94 avg=2.40\n","[452 | 1526.29] loss=1.57 avg=2.39\n","[453 | 1529.55] loss=2.37 avg=2.39\n","[454 | 1532.80] loss=2.07 avg=2.39\n","[455 | 1536.07] loss=1.79 avg=2.38\n","[456 | 1539.33] loss=1.85 avg=2.37\n","[457 | 1542.58] loss=2.31 avg=2.37\n","[458 | 1545.84] loss=1.64 avg=2.37\n","[459 | 1549.09] loss=2.15 avg=2.36\n","[460 | 1552.35] loss=2.03 avg=2.36\n","[461 | 1555.60] loss=1.90 avg=2.36\n","[462 | 1558.86] loss=1.67 avg=2.35\n","[463 | 1562.13] loss=2.07 avg=2.35\n","[464 | 1565.38] loss=1.96 avg=2.34\n","[465 | 1568.63] loss=1.92 avg=2.34\n","[466 | 1571.88] loss=2.40 avg=2.34\n","[467 | 1575.13] loss=1.79 avg=2.33\n","[468 | 1578.38] loss=2.16 avg=2.33\n","[469 | 1581.63] loss=2.29 avg=2.33\n","[470 | 1584.89] loss=1.99 avg=2.33\n","[471 | 1588.14] loss=1.84 avg=2.32\n","[472 | 1591.39] loss=1.48 avg=2.31\n","[473 | 1594.65] loss=1.68 avg=2.31\n","[474 | 1597.90] loss=2.20 avg=2.31\n","[475 | 1601.15] loss=1.94 avg=2.30\n","[476 | 1604.40] loss=2.10 avg=2.30\n","[477 | 1607.67] loss=1.98 avg=2.30\n","[478 | 1610.91] loss=1.55 avg=2.29\n","[479 | 1614.17] loss=1.65 avg=2.28\n","[480 | 1617.43] loss=1.91 avg=2.28\n","[481 | 1620.67] loss=2.09 avg=2.28\n","[482 | 1623.94] loss=2.40 avg=2.28\n","[483 | 1627.19] loss=1.68 avg=2.27\n","[484 | 1630.45] loss=1.66 avg=2.27\n","[485 | 1633.70] loss=1.73 avg=2.26\n","[486 | 1636.95] loss=2.20 avg=2.26\n","[487 | 1640.21] loss=1.97 avg=2.26\n","[488 | 1643.46] loss=2.00 avg=2.26\n","[489 | 1646.71] loss=2.41 avg=2.26\n","[490 | 1649.96] loss=1.78 avg=2.25\n","[491 | 1653.22] loss=1.73 avg=2.25\n","[492 | 1656.46] loss=1.79 avg=2.24\n","[493 | 1659.70] loss=1.43 avg=2.23\n","[494 | 1662.97] loss=1.83 avg=2.23\n","[495 | 1666.21] loss=1.85 avg=2.23\n","[496 | 1669.47] loss=1.90 avg=2.22\n","[497 | 1672.73] loss=2.05 avg=2.22\n","[498 | 1675.98] loss=2.03 avg=2.22\n","[499 | 1679.23] loss=1.90 avg=2.22\n","[500 | 1682.48] loss=1.93 avg=2.21\n","======== SAMPLE 1 ========\n","And you know of no other like it.\n","\n","CORIOLANUS:\n","Why, then, this is a worthy and advantageous\n","Villain: I'll tell him of thy state:\n","I had some conceit at the first sight he bore\n","But I was most glad to overlook it in\n","The sequel. O thou villain!\n","\n","LARTIUS:\n","No, Coriolanus; I am he.\n","\n","CORIOLANUS:\n","You're worthy to die?\n","\n","LARTIUS:\n","Yes, indeed:\n","And shall he live to see that day, we'll do't.\n","\n","CORIOLANUS:\n","And will he die? O yes; then, sirs.\n","\n","LARTIUS:\n","Very sure, sir.\n","\n","CORIOLANUS:\n","Why, then you have been talking of him;\n","I'll tell him of you. Tell him of your state,\n","And tell him in what fashion he deserves\n","A place of high honour: if he be not your\n","honour's soldier, then 'tis well that you should\n","wear your visage well.\n","\n","LARTIUS:\n","What's your honour's suit?\n","\n","CORIOLANUS:\n","Sir, I will not bide my life till I know\n","Which way to turn. My best army, sirs.,\n","As soon as Coriolanus will be\n","My comrade, I'll mounte my soldiers, though the\n","governor advise me\n","No, so I ha't. Fare ye well.\n","\n","LARTIUS:\n","So, I dare you: fare you well.\n","\n","CORIOLANUS:\n","As much as I like;\n","As truly as I vow.\n","\n","LARTIUS:\n","Vouchsafe to go: I'll bring them before the\n","people, and hear their reasons why.\n","\n","CORIOLANUS:\n","Your opinion; your consent; let them go; I warrant\n","them.\n","\n","LARTIUS:\n","I will think upon no other cause behind their\n","treason, but that I might have them retune to\n","me:\n","My friends, you will think upon no other cause.\n","\n","CORIOLANUS:\n","Foul wench!\n","\n","LARTIUS:\n","Not my friend?\n","\n","CORIOLANUS:\n","No, Lord Poliquin, Lord Carthage, Lord\n","Abbot of Corioli; whose tongue is my\n","weary husband.\n","\n","LARTIUS:\n","Thou canst not?\n","Caius Minutius, if thou\n","seem capable of such a thing, I will find him in Coriolo.\n","\n","CORIOLANUS:\n","O, thou wilt procure me.\n","\n","LARTIUS:\n","Then tell us,\n","What your general's opinion is: how gan to London beheaded\n","Sir Christopher, of the Volscian wars?\n","\n","CORIOLANUS:\n","Of your general's choice; for you are from\n","the Volscian wars too.\n","\n","LARTIUS:\n","You ne'er held a post for your men but\n","three years: I speak this as if I were\n","honourable men: come, Coriolanus,\n","tell these\n","rogues how they kill with slippers: there were\n","three years between your general's discharge and\n","your going to Corioli: but your general was\n","considered to be the more highly\n","brilliant among them.\n","\n","CORIOLANUS:\n","Then tell me,\n","for how near he is, what\n","fortune he is destined to become, and what's the\n","principle in Corioli, to keep\n","on his terms?\n","\n","LARTIUS:\n","For my son;\n","though he doth command that term: though he\n","shall ever be a Roman general, shall his\n","service, as an emperor, the more honour for him\n","than the call of duty.\n","\n","CORIOLANUS:\n","Now, tell me,\n","If Rome were as fair as she is, what would it\n","make Rome as fair as Corioli?\n","If she were as fair as she is, will she be\n","good as Corioli?\n","\n","LARTIUS:\n","Well, as she was thought by his mother to be\n","fair as she is, may be changed, she remains\n","better than she was thought by his father.\n","\n","CORIOLANUS:\n","The gods preserve\n","Heavens be ruled! O that my wisdom was\n","so wise! What is my state? I am not\n","provided but for myself: this is most\n","apparent of my youth, and most advantageous\n","to me: in my opinion Rome should become fair,\n","with her first right as an emperor; and here\n","\n","\n","[501 | 1698.24] loss=1.54 avg=2.21\n","[502 | 1701.49] loss=1.86 avg=2.20\n","[503 | 1704.72] loss=1.96 avg=2.20\n","[504 | 1707.97] loss=1.89 avg=2.20\n","[505 | 1711.23] loss=2.10 avg=2.20\n","[506 | 1714.48] loss=1.60 avg=2.19\n","[507 | 1717.74] loss=1.37 avg=2.18\n","[508 | 1720.99] loss=2.20 avg=2.18\n","[509 | 1724.24] loss=1.73 avg=2.18\n","[510 | 1727.50] loss=1.75 avg=2.17\n","[511 | 1730.74] loss=1.53 avg=2.17\n","[512 | 1734.01] loss=2.10 avg=2.17\n","[513 | 1737.26] loss=1.50 avg=2.16\n","[514 | 1740.51] loss=1.76 avg=2.16\n","[515 | 1743.77] loss=1.55 avg=2.15\n","[516 | 1747.02] loss=1.99 avg=2.15\n","[517 | 1750.28] loss=1.44 avg=2.14\n","[518 | 1753.53] loss=1.77 avg=2.14\n","[519 | 1756.78] loss=1.57 avg=2.13\n","[520 | 1760.03] loss=1.81 avg=2.13\n","[521 | 1763.27] loss=2.04 avg=2.13\n","[522 | 1766.53] loss=1.71 avg=2.12\n","[523 | 1769.78] loss=1.70 avg=2.12\n","[524 | 1773.04] loss=2.09 avg=2.12\n","[525 | 1776.29] loss=1.71 avg=2.11\n","[526 | 1779.54] loss=1.62 avg=2.11\n","[527 | 1782.79] loss=1.85 avg=2.11\n","[528 | 1786.02] loss=1.69 avg=2.10\n","[529 | 1789.26] loss=1.62 avg=2.10\n","[530 | 1792.52] loss=1.97 avg=2.10\n","[531 | 1795.74] loss=1.70 avg=2.09\n","[532 | 1798.99] loss=1.46 avg=2.09\n","[533 | 1802.26] loss=1.51 avg=2.08\n","[534 | 1805.51] loss=1.46 avg=2.07\n","[535 | 1808.77] loss=1.67 avg=2.07\n","[536 | 1812.04] loss=2.08 avg=2.07\n","[537 | 1815.29] loss=1.60 avg=2.07\n","[538 | 1818.55] loss=1.56 avg=2.06\n","[539 | 1821.80] loss=1.76 avg=2.06\n","[540 | 1825.05] loss=1.77 avg=2.05\n","[541 | 1828.31] loss=1.43 avg=2.05\n","[542 | 1831.56] loss=1.43 avg=2.04\n","[543 | 1834.82] loss=1.92 avg=2.04\n","[544 | 1838.07] loss=1.64 avg=2.04\n","[545 | 1841.33] loss=1.70 avg=2.03\n","[546 | 1844.58] loss=1.86 avg=2.03\n","[547 | 1847.83] loss=1.74 avg=2.03\n","[548 | 1851.07] loss=1.34 avg=2.02\n","[549 | 1854.31] loss=1.96 avg=2.02\n","[550 | 1857.57] loss=1.61 avg=2.02\n","[551 | 1860.83] loss=1.83 avg=2.02\n","[552 | 1864.07] loss=1.52 avg=2.01\n","[553 | 1867.34] loss=1.21 avg=2.00\n","[554 | 1870.59] loss=1.66 avg=2.00\n","[555 | 1873.83] loss=1.45 avg=1.99\n","[556 | 1877.08] loss=2.34 avg=2.00\n","[557 | 1880.33] loss=1.11 avg=1.99\n","[558 | 1883.58] loss=1.65 avg=1.98\n","[559 | 1886.84] loss=1.65 avg=1.98\n","[560 | 1890.10] loss=1.87 avg=1.98\n","[561 | 1893.33] loss=1.47 avg=1.98\n","[562 | 1896.58] loss=1.73 avg=1.97\n","[563 | 1899.84] loss=1.85 avg=1.97\n","[564 | 1903.08] loss=1.76 avg=1.97\n","[565 | 1906.33] loss=1.47 avg=1.96\n","[566 | 1909.58] loss=1.56 avg=1.96\n","[567 | 1912.83] loss=2.52 avg=1.97\n","[568 | 1916.09] loss=1.38 avg=1.96\n","[569 | 1919.35] loss=1.20 avg=1.95\n","[570 | 1922.60] loss=1.49 avg=1.95\n","[571 | 1925.85] loss=1.54 avg=1.94\n","[572 | 1929.11] loss=1.46 avg=1.94\n","[573 | 1932.37] loss=1.95 avg=1.94\n","[574 | 1935.62] loss=1.84 avg=1.94\n","[575 | 1938.87] loss=1.77 avg=1.94\n","[576 | 1942.12] loss=1.41 avg=1.93\n","[577 | 1945.37] loss=1.75 avg=1.93\n","[578 | 1948.63] loss=1.65 avg=1.93\n","[579 | 1951.88] loss=1.64 avg=1.92\n","[580 | 1955.13] loss=1.35 avg=1.92\n","[581 | 1958.39] loss=1.57 avg=1.91\n","[582 | 1961.64] loss=1.44 avg=1.91\n","[583 | 1964.90] loss=1.24 avg=1.90\n","[584 | 1968.15] loss=1.86 avg=1.90\n","[585 | 1971.40] loss=1.72 avg=1.90\n","[586 | 1974.66] loss=1.61 avg=1.90\n","[587 | 1977.91] loss=1.61 avg=1.89\n","[588 | 1981.15] loss=1.77 avg=1.89\n","[589 | 1984.40] loss=1.45 avg=1.89\n","[590 | 1987.67] loss=1.72 avg=1.89\n","[591 | 1990.92] loss=1.48 avg=1.88\n","[592 | 1994.16] loss=1.37 avg=1.88\n","[593 | 1997.43] loss=1.13 avg=1.87\n","[594 | 2000.67] loss=1.38 avg=1.87\n","[595 | 2003.94] loss=1.37 avg=1.86\n","[596 | 2007.18] loss=1.39 avg=1.86\n","[597 | 2010.44] loss=1.36 avg=1.85\n","[598 | 2013.70] loss=1.85 avg=1.85\n","[599 | 2016.97] loss=1.91 avg=1.85\n","[600 | 2020.22] loss=1.29 avg=1.85\n","======== SAMPLE 1 ========\n","\n","Gentlemen, take you up, that your time may prove a happy one.\n","\n","First Citizen:\n","It shall, gentlemen, afford us leisure\n","More than the state charges.\n","\n","HERMIONE:\n","O, it shall bless it; who is't glad\n","To lose her husband in this?\n","\n","GREMIO:\n","O, the most commendable is her courtesy:\n","I'll look for 'em on duty' day,\n","If ever they be here.\n","\n","CORIOLANUS:\n","So may you, good my friends:\n","To the mother of all good things, let her talk\n","About duty: you are an officer,\n","No sooner than 'tis believed, sir,\n","She shall have a full ear for all things state-born.\n","\n","SICINIUS:\n","Come, let's go:\n","She shall have a full hearing for all things state-born.\n","\n","CORIOLANUS:\n","Come, let's go!\n","I am auf dutch; will to Rome: let them both\n","Are happy they are state-born. I go:\n","Come, let's go!\n","Here's a little officer in view. What, you\n","mistress?\n","\n","ISABELLA:\n","My mother is auf dutch;\n","Her father is auf dutch; what ne'er then\n","Appear on the state books as such 'fore her age.\n","\n","CORIOLANUS:\n","I shall not keep silent, Isabel,\n","Nor I a peevish state will maintain\n","When so 'twere seen her birth as child.\n","\n","ISABELLA:\n","And all this while\n","I was plucked from the stock by my uncle.\n","\n","CORIOLANUS:\n","You shall have no halves of that, Isabel,\n","When such your wisdom shall bear truth.\n","\n","ISABELLA:\n","'Tis indeed the law: when the good aunt I was\n","Was married to the noble duke,--\n","\n","CORIOLANUS:\n","O, for a very thing, Isabel!\n","\n","ISABELLA:\n","And now, as I am sure\n","She thinks less of marriage than of the prince,\n","I promise you, she is a shrew;--\n","\n","CORIOLANUS:\n","I' the law!\n","O most kind cousin!\n","Were I as bold to take your niece,\n","Why, Isabel, there were many faults in you;\n","And therefore shall you know, I'll live by my deeds.\n","\n","Nurse:\n","\n","ISABELLA:\n","Faith, so is my lord.\n","\n","CORIOLANUS:\n","Tunis--\n","\n","DUKE VINCENTIO:\n","What, no warrant for it?\n","Isabela, what shall we do?\n","\n","ISABELLA:\n","We shall tell Isabela of what we know,\n","That her mind is a shrew; that she will say she is\n","a prince--\n","\n","DUKE VINCENTIO:\n","She shall not say you poor lie!\n","\n","ISABELLA:\n","By heavens, I'll say it right away.\n","\n","DUKE VINCENTIO:\n","And she shall not answer,\n","By heaven she answers like a prince.\n","\n","ISABELLA:\n","I am a duke,\n","And believe me, I'll beat them to their knees.\n","\n","DUKE VINCENTIO:\n","What shall we do?\n","\n","ISABELLA:\n","Shall we use our powers wisely?\n","\n","DUKE VINCENTIO:\n","If Isabela were noblewoman he was all noble,\n","As he was nobleman.\n","\n","ISABELLA:\n","But shall we swear we are not?\n","\n","DUKE VINCENTIO:\n","Ay, as I remember.\n","\n","ISABELLA:\n","No good is a rascal like you;\n","Unless you are a prince, I'll swear.\n","\n","DUKE VINCENTIO:\n","You are too rash.\n","\n","ISABELLA:\n","That is, as some I know, and none.\n","\n","DUKE VINCENTIO:\n","But that he knew you are a princess,--\n","\n","ISABELLA:\n","One which is named Camillo,--\n","\n","DUKE VINCENTIO:\n","And Camillo is princess: 'tis too foolish\n","To swear by 's.\n","\n","ISABELLA:\n","Isabelle shall be a duke.\n","\n","DUKE VINCENTIO:\n","'Tis she's a prince, Isabela.\n","\n","ISABELLA:\n","I do not believe her then when I see her:\n","I believe then when Isabela shall be called princess.\n","\n","DUKE VINCENTIO:\n","\n","[601 | 2035.87] loss=1.52 avg=1.84\n","[602 | 2039.13] loss=1.69 avg=1.84\n","[603 | 2042.38] loss=1.84 avg=1.84\n","[604 | 2045.61] loss=1.59 avg=1.84\n","[605 | 2048.87] loss=1.27 avg=1.83\n","[606 | 2052.12] loss=1.61 avg=1.83\n","[607 | 2055.38] loss=1.25 avg=1.82\n","[608 | 2058.63] loss=1.57 avg=1.82\n","[609 | 2061.88] loss=1.31 avg=1.82\n","[610 | 2065.14] loss=1.52 avg=1.81\n","[611 | 2068.39] loss=1.17 avg=1.81\n","[612 | 2071.65] loss=1.17 avg=1.80\n","[613 | 2074.90] loss=1.46 avg=1.80\n","[614 | 2078.15] loss=1.45 avg=1.79\n","[615 | 2081.39] loss=1.75 avg=1.79\n","[616 | 2084.64] loss=1.15 avg=1.79\n","[617 | 2087.89] loss=1.54 avg=1.79\n","[618 | 2091.15] loss=1.33 avg=1.78\n","[619 | 2094.39] loss=1.19 avg=1.77\n","[620 | 2097.65] loss=1.62 avg=1.77\n","[621 | 2100.90] loss=1.55 avg=1.77\n","[622 | 2104.17] loss=1.10 avg=1.76\n","[623 | 2107.42] loss=1.60 avg=1.76\n","[624 | 2110.67] loss=1.34 avg=1.76\n","[625 | 2113.92] loss=1.25 avg=1.75\n","[626 | 2117.17] loss=1.19 avg=1.75\n","[627 | 2120.43] loss=2.23 avg=1.75\n","[628 | 2123.68] loss=1.25 avg=1.75\n","[629 | 2126.94] loss=1.75 avg=1.75\n","[630 | 2130.17] loss=1.24 avg=1.74\n","[631 | 2133.42] loss=1.37 avg=1.74\n","[632 | 2136.68] loss=1.52 avg=1.74\n","[633 | 2139.94] loss=1.57 avg=1.73\n","[634 | 2143.18] loss=1.19 avg=1.73\n","[635 | 2146.44] loss=1.25 avg=1.72\n","[636 | 2149.72] loss=0.89 avg=1.72\n","[637 | 2152.97] loss=1.68 avg=1.72\n","[638 | 2156.22] loss=1.63 avg=1.71\n","[639 | 2159.46] loss=1.31 avg=1.71\n","[640 | 2162.71] loss=1.28 avg=1.71\n","[641 | 2165.97] loss=1.33 avg=1.70\n","[642 | 2169.23] loss=0.98 avg=1.70\n","[643 | 2172.49] loss=1.17 avg=1.69\n","[644 | 2175.75] loss=1.84 avg=1.69\n","[645 | 2179.00] loss=0.91 avg=1.68\n","[646 | 2182.26] loss=1.58 avg=1.68\n","[647 | 2185.51] loss=1.37 avg=1.68\n","[648 | 2188.76] loss=1.37 avg=1.68\n","[649 | 2192.02] loss=1.23 avg=1.67\n","[650 | 2195.27] loss=1.36 avg=1.67\n","[651 | 2198.53] loss=1.10 avg=1.66\n","[652 | 2201.78] loss=1.00 avg=1.66\n","[653 | 2205.03] loss=0.83 avg=1.65\n","[654 | 2208.28] loss=1.48 avg=1.65\n","[655 | 2211.53] loss=1.03 avg=1.64\n","[656 | 2214.79] loss=1.19 avg=1.64\n","[657 | 2218.04] loss=1.34 avg=1.63\n","[658 | 2221.29] loss=1.03 avg=1.63\n","[659 | 2224.53] loss=1.09 avg=1.62\n","[660 | 2227.79] loss=1.14 avg=1.62\n","[661 | 2231.04] loss=1.13 avg=1.61\n","[662 | 2234.30] loss=1.48 avg=1.61\n","[663 | 2237.54] loss=1.28 avg=1.61\n","[664 | 2240.81] loss=1.05 avg=1.60\n","[665 | 2244.06] loss=1.12 avg=1.60\n","[666 | 2247.32] loss=1.59 avg=1.60\n","[667 | 2250.57] loss=1.07 avg=1.59\n","[668 | 2253.82] loss=1.39 avg=1.59\n","[669 | 2257.08] loss=1.43 avg=1.59\n","[670 | 2260.33] loss=1.75 avg=1.59\n","[671 | 2263.59] loss=1.36 avg=1.59\n","[672 | 2266.84] loss=1.29 avg=1.58\n","[673 | 2270.09] loss=1.56 avg=1.58\n","[674 | 2273.35] loss=0.83 avg=1.58\n","[675 | 2276.60] loss=1.20 avg=1.57\n","[676 | 2279.84] loss=1.21 avg=1.57\n","[677 | 2283.09] loss=1.51 avg=1.57\n","[678 | 2286.34] loss=1.22 avg=1.57\n","[679 | 2289.58] loss=1.44 avg=1.56\n","[680 | 2292.84] loss=1.48 avg=1.56\n","[681 | 2296.10] loss=1.09 avg=1.56\n","[682 | 2299.36] loss=1.09 avg=1.55\n","[683 | 2302.61] loss=1.00 avg=1.55\n","[684 | 2305.87] loss=1.22 avg=1.54\n","[685 | 2309.13] loss=1.10 avg=1.54\n","[686 | 2312.38] loss=1.21 avg=1.54\n","[687 | 2315.63] loss=1.16 avg=1.53\n","[688 | 2318.89] loss=1.07 avg=1.53\n","[689 | 2322.17] loss=1.03 avg=1.52\n","[690 | 2325.41] loss=1.00 avg=1.52\n","[691 | 2328.67] loss=1.37 avg=1.52\n","[692 | 2331.92] loss=1.20 avg=1.51\n","[693 | 2335.19] loss=1.13 avg=1.51\n","[694 | 2338.45] loss=0.98 avg=1.50\n","[695 | 2341.71] loss=1.34 avg=1.50\n","[696 | 2344.96] loss=1.10 avg=1.50\n","[697 | 2348.21] loss=0.79 avg=1.49\n","[698 | 2351.47] loss=1.43 avg=1.49\n","[699 | 2354.72] loss=0.99 avg=1.49\n","[700 | 2357.98] loss=1.04 avg=1.48\n","======== SAMPLE 1 ========\n",", a single-piled deck, like an enigma,\n","Bound up with a con- stituted note:\n","With this tap I write, as now I read,\n","'Gramma museae.'\n","\n","BENVOLIO:\n","Gramma museae!\n","\n","Messenger:\n","I pray you,\n","Tell Lucio that I have the keys of this curio.\n","\n","BENVOLIO:\n","Gramma museae!\n","\n","Messenger:\n","Gramma museae!\n","\n","BENVOLIO:\n","Gramma museae!\n","\n","Messenger:\n","Gramma museae!\n","\n","BENVOLIO:\n","Gramma museae!\n","\n","Messenger:\n","Gramma museae!\n","\n","BENVOLIO:\n","Gramma museae!\n","\n","PERDITA:\n","You speak so well of her.\n","\n","BENVOLIO:\n","You might well say that.\n","\n","BENVOLIO:\n","I cannot agree with her every word.\n","\n","JULIET:\n","I wish my father were here with you.\n","\n","JULIET:\n","Your father here?\n","\n","BENVOLIO:\n","I would I knew he was.\n","\n","JULIET:\n","You knew him in Padua.\n","\n","BENVOLIO:\n","And lived with him?\n","\n","JULIET:\n","I could tell you he was.\n","\n","BENVOLIO:\n","Why, what is his name?\n","\n","JULIET:\n","Lucentio.\n","\n","BENVOLIO:\n","His name?\n","\n","JULIET:\n","Your name?\n","\n","BENVOLIO:\n","Your name?\n","\n","JULIET:\n","Your name?\n","\n","BENVOLIO:\n","Why, that's your name?\n","\n","JULIET:\n","I would it were so; wanting to know my son.\n","\n","BENVOLIO:\n","How long has his delay been?\n","\n","JULIET:\n","Two and twenty-three.\n","\n","BENVOLIO:\n","Why, that's as long\n","As an old woman waits upon her child's.\n","\n","JULIET:\n","'Tis more, that he is so new-adopted.\n","\n","BENVOLIO:\n","Why, that's no account of his age.\n","\n","JULIET:\n","'Tis young and very strange.\n","\n","BENVOLIO:\n","'Tis old and very strange.\n","\n","JULIET:\n","'Tis very odd that he should pronounce your name Lucentio.\n","\n","BENVOLIO:\n","Why then 'tis strange! Why then 'tis odd.\n","\n","JULIET:\n","Why then 'tis odd: he is three and twenty.\n","\n","BENVOLIO:\n","Why then 'tis odd: he is three and twenty and comes not close.\n","\n","JULIET:\n","Why then, 'tis odd: he is three and twenty and comes not close.\n","\n","BENVOLIO:\n","\n","JULIET:\n","\n","BENVOLIO:\n","\n","JULIET:\n","\n","BENVOLIO:\n","\n","JULIET:\n","\n","BENVOLIO:\n","\n","JULIET:\n","\n","PETRUCHIO:\n","\n","VINCENTIO:\n","\n","VOLUMNIA:\n","\n","BAPTISTA:\n","\n","VOLUMNIA:\n","\n","LUCENTIO:\n","\n","VOLUMNIA:\n","\n","JULIET:\n","\n","BAPTISTA:\n","\n","LUCENTIO:\n","\n","VOLUMNIA:\n","\n","JULIET:\n","\n","BAPTISTA:\n","\n","HORTENSIO:\n","\n","PETRUCHIO:\n","\n","HORTENSIO:\n","\n","PETRUCHIO:\n","\n","PETRUCHIO:\n","\n","HORTENSIO:\n","\n","HORTENSIO:\n","\n","PETRUCHIO:\n","\n","BAPTISTA:\n","\n","LUCENTIO:\n","\n","PETRUCHIO:\n","\n","PETRUCHIO:\n","\n","VINCENTIO:\n","\n","TRANIO:\n","\n","VINCENTIO:\n","\n","PETRUCHIO:\n","\n","HORTENSIO:\n","\n","BAPTISTA:\n","\n","TRANIO:\n","\n","PETRUCHIO:\n","\n","HORTENSIO:\n","\n","TRANIO:\n","\n","BAPTISTA:\n","\n","TRANIO:\n","\n","HORTENSIO:\n","\n","PETRUCHIO:\n","\n","BAPTISTA:\n","\n","TRANIO:\n","\n","HORTENSIO:\n","\n","PETRUCHIO:\n","\n","PETR\n","\n","[701 | 2373.62] loss=1.13 avg=1.48\n","[702 | 2376.88] loss=1.09 avg=1.47\n","[703 | 2380.13] loss=0.97 avg=1.47\n","[704 | 2383.38] loss=1.25 avg=1.47\n","[705 | 2386.64] loss=0.85 avg=1.46\n","[706 | 2389.89] loss=0.96 avg=1.46\n","[707 | 2393.15] loss=1.20 avg=1.45\n","[708 | 2396.40] loss=0.72 avg=1.45\n","[709 | 2399.67] loss=0.72 avg=1.44\n","[710 | 2402.93] loss=0.78 avg=1.43\n","[711 | 2406.18] loss=1.11 avg=1.43\n","[712 | 2409.44] loss=1.37 avg=1.43\n","[713 | 2412.71] loss=1.16 avg=1.43\n","[714 | 2415.97] loss=0.97 avg=1.42\n","[715 | 2419.22] loss=1.45 avg=1.42\n","[716 | 2422.47] loss=1.16 avg=1.42\n","[717 | 2425.72] loss=0.88 avg=1.41\n","[718 | 2428.98] loss=0.83 avg=1.41\n","[719 | 2432.24] loss=1.52 avg=1.41\n","[720 | 2435.49] loss=1.28 avg=1.41\n","[721 | 2438.74] loss=0.72 avg=1.40\n","[722 | 2441.97] loss=1.29 avg=1.40\n","[723 | 2445.23] loss=1.39 avg=1.40\n","[724 | 2448.48] loss=1.33 avg=1.40\n","[725 | 2451.73] loss=1.21 avg=1.40\n","[726 | 2454.99] loss=1.23 avg=1.40\n","[727 | 2458.23] loss=1.27 avg=1.39\n","[728 | 2461.48] loss=1.05 avg=1.39\n","[729 | 2464.73] loss=0.83 avg=1.38\n","[730 | 2467.98] loss=0.91 avg=1.38\n","[731 | 2471.24] loss=1.07 avg=1.38\n","[732 | 2474.50] loss=1.05 avg=1.37\n","[733 | 2477.75] loss=1.05 avg=1.37\n","[734 | 2481.00] loss=0.82 avg=1.36\n","[735 | 2484.25] loss=1.33 avg=1.36\n","[736 | 2487.51] loss=0.80 avg=1.36\n","[737 | 2490.76] loss=1.11 avg=1.36\n","[738 | 2494.01] loss=0.81 avg=1.35\n","[739 | 2497.27] loss=0.89 avg=1.35\n","[740 | 2500.51] loss=1.00 avg=1.34\n","[741 | 2503.77] loss=1.30 avg=1.34\n","[742 | 2507.03] loss=0.99 avg=1.34\n","[743 | 2510.28] loss=0.89 avg=1.33\n","[744 | 2513.53] loss=0.98 avg=1.33\n","[745 | 2516.79] loss=0.79 avg=1.33\n","[746 | 2520.04] loss=0.62 avg=1.32\n","[747 | 2523.29] loss=0.96 avg=1.31\n","[748 | 2526.55] loss=0.89 avg=1.31\n","[749 | 2529.81] loss=0.96 avg=1.31\n","[750 | 2533.05] loss=0.72 avg=1.30\n","[751 | 2536.32] loss=1.11 avg=1.30\n","[752 | 2539.57] loss=0.92 avg=1.30\n","[753 | 2542.84] loss=0.74 avg=1.29\n","[754 | 2546.10] loss=0.99 avg=1.29\n","[755 | 2549.35] loss=1.33 avg=1.29\n","[756 | 2552.61] loss=0.92 avg=1.28\n","[757 | 2555.86] loss=1.03 avg=1.28\n","[758 | 2559.11] loss=1.23 avg=1.28\n","[759 | 2562.37] loss=0.69 avg=1.27\n","[760 | 2565.62] loss=0.88 avg=1.27\n","[761 | 2568.88] loss=0.88 avg=1.27\n","[762 | 2572.13] loss=0.94 avg=1.26\n","[763 | 2575.39] loss=0.83 avg=1.26\n","[764 | 2578.65] loss=1.59 avg=1.26\n","[765 | 2581.91] loss=0.59 avg=1.26\n","[766 | 2585.17] loss=0.90 avg=1.25\n","[767 | 2588.42] loss=1.03 avg=1.25\n","[768 | 2591.67] loss=1.18 avg=1.25\n","[769 | 2594.92] loss=0.67 avg=1.24\n","[770 | 2598.18] loss=0.67 avg=1.24\n","[771 | 2601.44] loss=0.57 avg=1.23\n","[772 | 2604.69] loss=0.58 avg=1.22\n","[773 | 2607.94] loss=0.87 avg=1.22\n","[774 | 2611.20] loss=0.63 avg=1.22\n","[775 | 2614.45] loss=0.87 avg=1.21\n","[776 | 2617.70] loss=1.23 avg=1.21\n","[777 | 2620.95] loss=0.82 avg=1.21\n","[778 | 2624.21] loss=0.88 avg=1.20\n","[779 | 2627.47] loss=0.91 avg=1.20\n","[780 | 2630.72] loss=1.13 avg=1.20\n","[781 | 2633.98] loss=0.79 avg=1.20\n","[782 | 2637.24] loss=0.74 avg=1.19\n","[783 | 2640.51] loss=0.82 avg=1.19\n","[784 | 2643.76] loss=0.69 avg=1.18\n","[785 | 2647.02] loss=0.88 avg=1.18\n","[786 | 2650.27] loss=0.64 avg=1.18\n","[787 | 2653.52] loss=1.16 avg=1.18\n","[788 | 2656.77] loss=0.79 avg=1.17\n","[789 | 2660.04] loss=0.78 avg=1.17\n","[790 | 2663.28] loss=0.76 avg=1.16\n","[791 | 2666.53] loss=0.90 avg=1.16\n","[792 | 2669.78] loss=0.68 avg=1.16\n","[793 | 2673.04] loss=1.18 avg=1.16\n","[794 | 2676.29] loss=0.70 avg=1.15\n","[795 | 2679.55] loss=0.72 avg=1.15\n","[796 | 2682.82] loss=0.78 avg=1.14\n","[797 | 2686.08] loss=0.62 avg=1.14\n","[798 | 2689.33] loss=1.04 avg=1.14\n","[799 | 2692.59] loss=0.80 avg=1.13\n","[800 | 2695.84] loss=0.57 avg=1.13\n","======== SAMPLE 1 ========\n","And the very air and heavens! And, to make you faint, the bones of thy horses' bones!\n","And the very stones!\n","\n","CATESBY:\n","The very stones!\n","\n","RIVERS:\n","And, to make you faint, their voices!\n","\n","CATESBY:\n","Their voices!\n","\n","RIVERS:\n","Which I distinctly swear to\n","Never from the mouth of man nor woman\n","Beble thee but with such terror that thee\n","Can hear a man or woman speak.\n","\n","LUCENTIO:\n","Come, no more; I will not go in on them.\n","\n","BIANCA:\n","But were you then of my blood, my love, and\n","My faith, as now you are, that would consent\n","To divide my body into a school,\n","A bed, a bed-cup, a pillow,\n","A mantle, a bed-sheet,--\n","\n","LUCENTIO:\n","Good sir, you mistake no;\n","The two sedges which you divide\n","Are one that sprawls about the roof,\n","Another that frowns.\n","\n","BIANCA:\n","I speak no more; I will go call one of them.\n","\n","RIVERS:\n","Good my lord,--\n","\n","BIANCA:\n","Go; you may not bid me.\n","\n","RIVERS:\n","Good sir,--\n","\n","LUCENTIO:\n","You do not bid me sir, nor do you bid me any thing,\n","But you bid me lay on my face a napkin,\n","And say 'I thank the gods.'\n","\n","BENVOLIO:\n","And I--\n","\n","LUCENTIO:\n","I thank the gods, good sir, that you do.\n","\n","BENVOLIO:\n","Thank your gods, good man, and say what\n","You thank'd by threatening the gods:\n","For what you owe the gods, in me--\n","\n","LUCENTIO:\n","What I owe--\n","\n","BENVOLIO:\n","What can you command, good man?\n","\n","LUCENTIO:\n","My name is Benedick, and I am keeper of the\n","snow-machines.\n","\n","RIVERS:\n","Good lord, give me some food; I must have\n","this hot supper at twelve P.M.\n","I am hungry, and will not go to the feast.\n","\n","BIANCA:\n","You give'st bounty but for the grace of God.\n","\n","LUCENTIO:\n","Not my word, but that I must.\n","\n","BIANCA:\n","Then it is mine, and not my name.\n","\n","RIVERS:\n","Who told you of this?\n","\n","LUCENTIO:\n","You that went with me before?\n","\n","RIVERS:\n","I that saw this coming, which saw it presently,--\n","I'll the supper sit down; for you are come too late.\n","\n","BENVOLIO:\n","Nay, but you lie, good man, and deny to come;\n","but I'll the supper be?\n","\n","RIVERS:\n","What if I deny? no; this is not the way.\n","\n","BENVOLIO:\n","You lie, honest man; you must go with the light.\n","How now! who is there?\n","\n","Pedant:\n","The priest comes by, who is come by.\n","\n","BAPTISTA:\n","How! must we all agree\n","In this our mutual suspicion?\n","\n","GRUMIO:\n","How now! must we all agree\n","In this our mutual suspicion?\n","\n","BAPTISTA:\n","What then?\n","\n","GRUMIO:\n","What then?\n","\n","BAPTISTA:\n","How now! must we all agree\n","In that our mis-settling places are agree'd\n","In some something.\n","\n","TRANIO:\n","Pardon, Priscilla; I will be your cheese.\n","\n","BAPTISTA:\n","I am glad to see your favour, and am you glad\n","To see your favour; but yet, yet your liking\n","Is strange to behold me here, and meamed\n","To see your liking: must I not be glad\n","To see my cousin?\n","\n","GRUMIO:\n","Ah, yes, yes, yes, yes; yes, yes; yes;\n","yes; yes; yes! O, yes! Come, let's go.\n","\n","BAPTISTA:\n","What is his name?\n","\n","GRUMIO:\n","Biondello, sir.\n","\n","BIONDELLO:\n","Biondello, sir.\n","\n","GRUMIO:\n","Biondello, sir.\n","\n","GREMIO:\n","Biondello, sir.\n","\n","BIONDELLO:\n","Biondello, sir! Please you, please you. Can you swear\n","That you never heard a r\n","\n","[801 | 2711.50] loss=0.67 avg=1.12\n","[802 | 2714.74] loss=0.70 avg=1.12\n","[803 | 2718.01] loss=0.82 avg=1.12\n","[804 | 2721.25] loss=0.85 avg=1.11\n","[805 | 2724.52] loss=1.12 avg=1.11\n","[806 | 2727.77] loss=0.66 avg=1.11\n","[807 | 2731.01] loss=1.35 avg=1.11\n","[808 | 2734.27] loss=0.68 avg=1.11\n","[809 | 2737.53] loss=1.02 avg=1.11\n","[810 | 2740.78] loss=0.69 avg=1.10\n","[811 | 2744.04] loss=0.66 avg=1.10\n","[812 | 2747.28] loss=0.84 avg=1.10\n","[813 | 2750.54] loss=0.92 avg=1.09\n","[814 | 2753.79] loss=0.49 avg=1.09\n","[815 | 2757.05] loss=0.67 avg=1.08\n","[816 | 2760.29] loss=0.62 avg=1.08\n","[817 | 2763.55] loss=0.54 avg=1.07\n","[818 | 2766.79] loss=0.55 avg=1.07\n","[819 | 2770.04] loss=0.59 avg=1.06\n","[820 | 2773.29] loss=0.53 avg=1.06\n","[821 | 2776.55] loss=0.60 avg=1.05\n","[822 | 2779.79] loss=0.76 avg=1.05\n","[823 | 2783.05] loss=0.71 avg=1.05\n","[824 | 2786.29] loss=0.44 avg=1.04\n","[825 | 2789.54] loss=0.87 avg=1.04\n","[826 | 2792.80] loss=0.74 avg=1.04\n","[827 | 2796.04] loss=0.67 avg=1.03\n","[828 | 2799.31] loss=0.77 avg=1.03\n","[829 | 2802.55] loss=0.65 avg=1.03\n","[830 | 2805.81] loss=0.77 avg=1.02\n","[831 | 2809.09] loss=0.75 avg=1.02\n","[832 | 2812.34] loss=0.47 avg=1.02\n","[833 | 2815.59] loss=0.76 avg=1.01\n","[834 | 2818.86] loss=0.70 avg=1.01\n","[835 | 2822.11] loss=0.58 avg=1.01\n","[836 | 2825.36] loss=0.64 avg=1.00\n","[837 | 2828.60] loss=0.79 avg=1.00\n","[838 | 2831.86] loss=0.58 avg=1.00\n","[839 | 2835.11] loss=0.76 avg=0.99\n","[840 | 2838.36] loss=0.44 avg=0.99\n","[841 | 2841.62] loss=1.00 avg=0.99\n","[842 | 2844.87] loss=0.79 avg=0.99\n","[843 | 2848.13] loss=0.39 avg=0.98\n","[844 | 2851.38] loss=0.64 avg=0.98\n","[845 | 2854.64] loss=0.55 avg=0.97\n","[846 | 2857.88] loss=0.64 avg=0.97\n","[847 | 2861.14] loss=0.73 avg=0.97\n","[848 | 2864.37] loss=0.92 avg=0.97\n","[849 | 2867.62] loss=0.41 avg=0.96\n","[850 | 2870.88] loss=0.56 avg=0.96\n","[851 | 2874.13] loss=0.53 avg=0.95\n","[852 | 2877.38] loss=0.52 avg=0.95\n","[853 | 2880.64] loss=0.62 avg=0.94\n","[854 | 2883.89] loss=0.71 avg=0.94\n","[855 | 2887.15] loss=0.39 avg=0.94\n","[856 | 2890.41] loss=0.48 avg=0.93\n","[857 | 2893.66] loss=0.72 avg=0.93\n","[858 | 2896.92] loss=0.41 avg=0.92\n","[859 | 2900.16] loss=0.81 avg=0.92\n","[860 | 2903.42] loss=0.61 avg=0.92\n","[861 | 2906.67] loss=0.55 avg=0.92\n","[862 | 2909.93] loss=0.90 avg=0.92\n","[863 | 2913.19] loss=0.51 avg=0.91\n","[864 | 2916.44] loss=0.51 avg=0.91\n","[865 | 2919.69] loss=0.79 avg=0.91\n","[866 | 2922.94] loss=0.45 avg=0.90\n","[867 | 2926.18] loss=0.60 avg=0.90\n","[868 | 2929.41] loss=0.81 avg=0.90\n","[869 | 2932.66] loss=0.80 avg=0.90\n","[870 | 2935.93] loss=0.60 avg=0.89\n","[871 | 2939.17] loss=0.72 avg=0.89\n","[872 | 2942.42] loss=0.51 avg=0.89\n","[873 | 2945.69] loss=0.62 avg=0.89\n","[874 | 2948.93] loss=0.73 avg=0.89\n","[875 | 2952.20] loss=0.65 avg=0.88\n","[876 | 2955.44] loss=0.66 avg=0.88\n","[877 | 2958.69] loss=0.77 avg=0.88\n","[878 | 2961.94] loss=0.51 avg=0.88\n","[879 | 2965.20] loss=0.71 avg=0.87\n","[880 | 2968.46] loss=0.56 avg=0.87\n","[881 | 2971.73] loss=0.55 avg=0.87\n","[882 | 2975.00] loss=0.70 avg=0.87\n","[883 | 2978.26] loss=0.51 avg=0.86\n","[884 | 2981.52] loss=0.47 avg=0.86\n","[885 | 2984.77] loss=0.58 avg=0.86\n","[886 | 2988.03] loss=0.44 avg=0.85\n","[887 | 2991.29] loss=0.49 avg=0.85\n","[888 | 2994.54] loss=0.47 avg=0.84\n","[889 | 2997.79] loss=0.37 avg=0.84\n","[890 | 3001.04] loss=0.72 avg=0.84\n","[891 | 3004.30] loss=0.41 avg=0.83\n","[892 | 3007.55] loss=0.53 avg=0.83\n","[893 | 3010.80] loss=0.46 avg=0.83\n","[894 | 3014.06] loss=0.56 avg=0.82\n","[895 | 3017.31] loss=0.62 avg=0.82\n","[896 | 3020.57] loss=0.46 avg=0.82\n","[897 | 3023.84] loss=0.59 avg=0.82\n","[898 | 3027.08] loss=0.41 avg=0.81\n","[899 | 3030.34] loss=0.43 avg=0.81\n","[900 | 3033.59] loss=0.70 avg=0.81\n","======== SAMPLE 1 ========\n"," of my state, as now I reign!\n","\n","GLOUCESTER:\n","The most noble Lord of Derby,\n","If he be there, to strike breath upon breath,\n","And see what triumphal triumphalism\n","Becomes in this unhappy circuit!\n","\n","BUCKINGHAM:\n","You do the honourable thing,\n","By moving the subjection of the people\n","To such a sudden outrage: but I fear\n","Our south-east-port already has swept\n","In to our north, and made the wheels of justice\n","Twice too fast turning the rampart to the main!\n","\n","CLARENCE:\n","Who's that, then?\n","\n","GLOUCESTER:\n","My lord, he is desperately outed,\n","Because his old party holds sway in the people,\n","Evening import, not to all the city.\n","\n","KING EDWARD IV:\n","How darkly in nature\n","Whiles I shine, shows himself in form,\n","Dared to stand, with form so heavily flayed,\n","Stand as apparent from my sight\n","As from a night-crow to a black-sky,\n","Evening from my mind, as from a devil's eye,\n","Subject to my powerful eye, I, not his master,\n","Have made his darkness my guide.\n","My old favour, Plantagenet, my loving lord!\n","Thou wert best, when thou didst tentacled,\n","But only for a tyrant's bleaching,\n","To gaze on thy neighbour's estate,\n","His grave, his state, his flattering dust,\n","His state his parks, and with his brow wrinkled\n","Turn'd in any scowl or bow-legged mean to see,\n","Did but stare in such a dire business,\n","And left his honour and his state,\n","Which often dovetails with grim depravity,\n","To frown in misery, like an irredeemer:\n","So you do set the tyrant on the sword\n","Of my poor soul, and not on him that sets\n","A man at death on his sword-bound knee.\n","I bear this present to my mother,\n","Thy air of constable beseeming me;\n","And it seems to suck no joy from me,\n","Being but to blame for my poor state.\n","\n","QUEEN MARGARET:\n","Good morrow to hear good news;\n","As much good news as I can find to thrust\n","Ere you cross the Alps; and when you hear\n","The crook-backing of the bitter sea,\n","The rumbling of trumpets and the din of musk,\n","Hear not that the savage fear o' the Belgians\n","Hath robbed your country. Fear and trembling doubt\n","Hath made you cross the seas, and now you lie\n","On the bed of the gentle ocean.\n","\n","Shepherd:\n","I am afraid, my lord,\n","The most certain of this is your loss.\n","\n","GLOUCESTER:\n","Fear not, my lord,\n","I'll hear you on the way. I saw the boar here in\n","the parks, yea, and bear to you the hair\n","there; and, beholding your loss, lo, thus:\n","The man that slew thy good son fear 'twill be\n","tail.\n","\n","Shepherd:\n","Here is the thing. A corse! but belike, here\n","is what I desire: a goodly nose,\n","Good eye, and a body of grace; a head,\n","An earthly looking serpent, abingled\n","By some eldritch device; a body\n","Remaining in her sick restlessness, not\n","Being led thence: these are the things\n","That deposed me; seducing my love:\n","Which, when I am led thence, comes back seductively\n","Unto some eldritch counsell; who if I come\n","not with child, find nothing but very woman\n","To suck her breath and stink for no man. But come\n","trustifully, my lord.\n","\n","AUTLOMER:\n","A woeful conceit!\n","\n","HASTINGS:\n","The shadow of our treasons! Yet look to see them!\n","I am like to dream on these things, my lady,\n","That every knit knot is unstuck'd, and every slip\n","Never go out of him. I go to sleep,\n","And then I come to myself, dreaming on't.\n","\n","AUTOLYC:\n","How now! does my lord approve me thus?\n","\n","HASTINGS:\n","I cannot choose but laugh at such things,\n","Or do my dishes in his company; my mind then\n","Become all those of mine house; my tongue\n","With idle whining moan of myself,\n","Whols and blows like mad men about each other.\n","So, now I beheld a dream of a wife,\n","And by such help of fortune's charm at once\n","To take her hence and to put\n","\n","[901 | 3049.71] loss=0.49 avg=0.80\n","[902 | 3052.97] loss=0.72 avg=0.80\n","[903 | 3056.21] loss=0.48 avg=0.80\n","[904 | 3059.47] loss=0.37 avg=0.80\n","[905 | 3062.72] loss=0.39 avg=0.79\n","[906 | 3065.98] loss=0.40 avg=0.79\n","[907 | 3069.23] loss=0.49 avg=0.79\n","[908 | 3072.49] loss=0.61 avg=0.78\n","[909 | 3075.74] loss=0.47 avg=0.78\n","[910 | 3079.00] loss=0.63 avg=0.78\n","[911 | 3082.25] loss=0.33 avg=0.77\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v9w85aJVYbq-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}